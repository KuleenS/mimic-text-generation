{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Discharge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import string\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "import scispacy\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "import random\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the mimic database and set the search path to the 'mimiciii' schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbschema='mimiciii'\n",
    "cnx = sqlalchemy.create_engine('postgresql+psycopg2://aa5118:mimic@localhost:5432/mimic',\n",
    "                    connect_args={'options': '-csearch_path={}'.format(dbschema)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the discharge summary notes joined on to patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>145834</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2101-10-31</td>\n",
       "      <td>44005</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2143-05-12</td>\n",
       "      <td>F</td>\n",
       "      <td>185777</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2191-03-23</td>\n",
       "      <td>4788</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2109-06-21</td>\n",
       "      <td>F</td>\n",
       "      <td>107064</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2175-06-15</td>\n",
       "      <td>20825</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>57115</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Name:  [**Known lastname 10050**], [**Known fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-13</td>\n",
       "      <td>20070</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Admission Date:  [**2149-11-9**]       Dischar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender  hadm_id           category  chartdate  \\\n",
       "0           3 2025-04-11      M   145834  Discharge summary 2101-10-31   \n",
       "1           4 2143-05-12      F   185777  Discharge summary 2191-03-23   \n",
       "2           6 2109-06-21      F   107064  Discharge summary 2175-06-15   \n",
       "3           9 2108-01-26      M   150750  Discharge summary 2149-11-14   \n",
       "4           9 2108-01-26      M   150750  Discharge summary 2149-11-13   \n",
       "\n",
       "   row_id  age_at_noteevent                                               text  \n",
       "0   44005              77.0  Admission Date:  [**2101-10-20**]     Discharg...  \n",
       "1    4788              48.0  Admission Date:  [**2191-3-16**]     Discharge...  \n",
       "2   20825              66.0  Admission Date: [**2175-5-30**]        Dischar...  \n",
       "3   57115              42.0  Name:  [**Known lastname 10050**], [**Known fi...  \n",
       "4   20070              42.0  Admission Date:  [**2149-11-9**]       Dischar...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "  SELECT\n",
    "      p.subject_id, p.dob, p.gender,\n",
    "      n.hadm_id, n.category, n.chartdate, n.row_id,\n",
    "      ROUND((cast(chartdate as date) - cast(dob as date)) / 365.242,0)\n",
    "          AS age_at_noteevent,\n",
    "      n.text\n",
    "  FROM patients p \n",
    "  INNER JOIN noteevents n \n",
    "  ON p.subject_id = n.subject_id\n",
    "  WHERE ROUND((cast(chartdate as date) - cast(dob as date)) / 365.242,0) > 14\n",
    "  AND n.category = 'Discharge summary'\n",
    "  ORDER BY subject_id\n",
    "  --LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sqlalchemy.text(sql), cnx)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change data type of age to the smallest possible type of integer to save memory and get rid of decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>145834</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2101-10-31</td>\n",
       "      <td>44005</td>\n",
       "      <td>77</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2143-05-12</td>\n",
       "      <td>F</td>\n",
       "      <td>185777</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2191-03-23</td>\n",
       "      <td>4788</td>\n",
       "      <td>48</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2109-06-21</td>\n",
       "      <td>F</td>\n",
       "      <td>107064</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2175-06-15</td>\n",
       "      <td>20825</td>\n",
       "      <td>66</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>57115</td>\n",
       "      <td>42</td>\n",
       "      <td>Name:  [**Known lastname 10050**], [**Known fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-13</td>\n",
       "      <td>20070</td>\n",
       "      <td>42</td>\n",
       "      <td>Admission Date:  [**2149-11-9**]       Dischar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender  hadm_id           category  chartdate  \\\n",
       "0           3 2025-04-11      M   145834  Discharge summary 2101-10-31   \n",
       "1           4 2143-05-12      F   185777  Discharge summary 2191-03-23   \n",
       "2           6 2109-06-21      F   107064  Discharge summary 2175-06-15   \n",
       "3           9 2108-01-26      M   150750  Discharge summary 2149-11-14   \n",
       "4           9 2108-01-26      M   150750  Discharge summary 2149-11-13   \n",
       "\n",
       "   row_id  age_at_noteevent                                               text  \n",
       "0   44005                77  Admission Date:  [**2101-10-20**]     Discharg...  \n",
       "1    4788                48  Admission Date:  [**2191-3-16**]     Discharge...  \n",
       "2   20825                66  Admission Date: [**2175-5-30**]        Dischar...  \n",
       "3   57115                42  Name:  [**Known lastname 10050**], [**Known fi...  \n",
       "4   20070                42  Admission Date:  [**2149-11-9**]       Dischar...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age_at_noteevent'] = pd.to_numeric(df['age_at_noteevent'], downcast='integer')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55404, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55404 'adult' (15 or over) discharge summaries - this is what we expect from our exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following punctuation marks frequently appear in the middle of words or between words without spacing meaning they are missed by the tokenizer. What we need to is to split the tokens on these punctuation marks after we have tokenized. We do this with regex. We then retokenize. This will substantially decreases the number of our unique words which we will replace with <UNK>\n",
    "\n",
    "- ampersand\n",
    "- brackets\n",
    "- colons\n",
    "- forward slashes(make sure to leave dates alone though)\n",
    "- full stops\n",
    "- hyphens\n",
    "- equals signs\n",
    "- semicolons\n",
    "- plus signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_regex = re.compile(r'([0-9])-([0-9][0-9]?)-([0-9])') # change date format so spacy can recognise\n",
    "newline_regex = re.compile(r'(\\\\n){3,}') # cap number of consecutive newline characters to 2\n",
    "newline_regex2 = re.compile(r'(\\\\r){3,}') # cap number of consecutive newline characters to 2\n",
    "ellipsis_regex = re.compile(r'(\\.){2,}')\n",
    "tilda_mult_regex = re.compile(r'(~){2,}')\n",
    "atsign_mult_regex = re.compile(r'(@){2,}')\n",
    "\n",
    "bracket_regex = re.compile(r'(.)(\\()(.)')\n",
    "bracket_regex2 = re.compile(r'(.)(\\))(.)')\n",
    "slash_regex = re.compile(r'(.)(\\/)([^0-9])')\n",
    "slash_regex2 = re.compile(r'([^0-9])(\\/)(.)')\n",
    "equals_regex = re.compile(r'(.)(=)(.)')\n",
    "colon_regex = re.compile(r'(.)(:)(.)')\n",
    "sq_bracket_regex = re.compile(r'(.)(\\[)(.)')\n",
    "dash_regex = re.compile(r'(.)(-)(.)')\n",
    "dash_regex2 = re.compile(r'(-)([\\S])')\n",
    "plus_regex = re.compile(r'(.)(\\+)(.)')\n",
    "amp_regex = re.compile(r'(.)(&)(.)')\n",
    "star_regex = re.compile(r'(.)(\\*)(.)') \n",
    "comma_regex = re.compile(r'(.)(,)(.)')\n",
    "tilda_regex = re.compile(r'(.)(~)(.)')\n",
    "pipe_regex = re.compile(r'(.)(\\|)(.)')\n",
    "atsign_regex = re.compile(r'(.)(@)(.)')\n",
    "dot_regex = re.compile(r'([^.][^0-9])(\\.)([^0-9,][^.])')\n",
    "\n",
    "dot_regex2 = re.compile(r'([^0-9])(\\.)(.)')\n",
    "semicol_regex = re.compile(r'(.);(.)')\n",
    "caret_regex = re.compile(r'(.)\\^(.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_sci_md') # sciSpaCy\n",
    "\n",
    "nlp.tokenizer.add_special_case(u'<PAR>', [{ORTH: u'<PAR>'}])\n",
    "nlp.tokenizer.add_special_case(u'<UNK>', [{ORTH: u'<UNK>'}])\n",
    "\n",
    "i = 0\n",
    "\n",
    "def tokenise_text(text, counter):\n",
    "    global i\n",
    "    \n",
    "    text = str(text)\n",
    "    text = date_regex.sub(r'\\1/\\2/\\3',text)\n",
    "    text = newline_regex.sub(r' \\\\n\\\\n ',text)\n",
    "    text = newline_regex2.sub(r' \\\\n\\\\n ',text)\n",
    "    text = ellipsis_regex.sub(r'.',text)\n",
    "    text = tilda_mult_regex.sub(r'~',text)\n",
    "    text = atsign_mult_regex.sub(r'@',text)\n",
    "    \n",
    "    text = text.replace(\"[**\",\"[\").replace(\"**]\",\"]\")\n",
    "    \n",
    "    tokens = nlp.tokenizer(text)\n",
    "    tokenised_text = \"\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        tokenised_text = tokenised_text + token.text + \" \"\n",
    "    \n",
    "    tokenised_text = tokenised_text.replace(\"\\n\",\" <PAR> \")\n",
    "    \n",
    "    tokenised_text = bracket_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = bracket_regex2.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = slash_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = slash_regex2.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = slash_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = equals_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = colon_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = sq_bracket_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dash_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dash_regex.sub(r'\\1 \\2 \\3',tokenised_text) # dash twice because sometimes it appears twice\n",
    "    tokenised_text = dash_regex.sub(r'\\1 \\2 \\3',tokenised_text) # dash thrice because sometimes it appears thrice\n",
    "    tokenised_text = dash_regex2.sub(r'\\1 \\2',tokenised_text) # dash thrice because sometimes it appears thrice\n",
    "    tokenised_text = plus_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = star_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = amp_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = comma_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dot_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = atsign_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = tilda_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = pipe_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dot_regex2.sub(r'\\1 \\3',tokenised_text)\n",
    "    tokenised_text = semicol_regex.sub(r'\\1 \\2',tokenised_text)\n",
    "    tokenised_text = caret_regex.sub(r'\\1 \\2',tokenised_text)\n",
    "        \n",
    "    tokenised_text = ' '.join(tokenised_text.split())\n",
    "    \n",
    "    tokens = nlp.tokenizer(tokenised_text)\n",
    "    tokenised_text = \"\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        tokenised_text = tokenised_text + token.text + \" \"\n",
    "    \n",
    "    counter.update(tokenised_text.lower().split())\n",
    "    \n",
    "    i += 1\n",
    "    if (i % 100) == 0:\n",
    "        print (i)\n",
    "    \n",
    "    return tokenised_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n",
      "40100\n",
      "40200\n",
      "40300\n",
      "40400\n",
      "40500\n",
      "40600\n",
      "40700\n",
      "40800\n",
      "40900\n",
      "41000\n",
      "41100\n",
      "41200\n",
      "41300\n",
      "41400\n",
      "41500\n",
      "41600\n",
      "41700\n",
      "41800\n",
      "41900\n",
      "42000\n",
      "42100\n",
      "42200\n",
      "42300\n",
      "42400\n",
      "42500\n",
      "42600\n",
      "42700\n",
      "42800\n",
      "42900\n",
      "43000\n",
      "43100\n",
      "43200\n",
      "43300\n",
      "43400\n",
      "43500\n",
      "43600\n",
      "43700\n",
      "43800\n",
      "43900\n",
      "44000\n",
      "44100\n",
      "44200\n",
      "44300\n",
      "44400\n",
      "44500\n",
      "44600\n",
      "44700\n",
      "44800\n",
      "44900\n",
      "45000\n",
      "45100\n",
      "45200\n",
      "45300\n",
      "45400\n",
      "45500\n",
      "45600\n",
      "45700\n",
      "45800\n",
      "45900\n",
      "46000\n",
      "46100\n",
      "46200\n",
      "46300\n",
      "46400\n",
      "46500\n",
      "46600\n",
      "46700\n",
      "46800\n",
      "46900\n",
      "47000\n",
      "47100\n",
      "47200\n",
      "47300\n",
      "47400\n",
      "47500\n",
      "47600\n",
      "47700\n",
      "47800\n",
      "47900\n",
      "48000\n",
      "48100\n",
      "48200\n",
      "48300\n",
      "48400\n",
      "48500\n",
      "48600\n",
      "48700\n",
      "48800\n",
      "48900\n",
      "49000\n",
      "49100\n",
      "49200\n",
      "49300\n",
      "49400\n",
      "49500\n",
      "49600\n",
      "49700\n",
      "49800\n",
      "49900\n",
      "50000\n",
      "50100\n",
      "50200\n",
      "50300\n",
      "50400\n",
      "50500\n",
      "50600\n",
      "50700\n",
      "50800\n",
      "50900\n",
      "51000\n",
      "51100\n",
      "51200\n",
      "51300\n",
      "51400\n",
      "51500\n",
      "51600\n",
      "51700\n",
      "51800\n",
      "51900\n",
      "52000\n",
      "52100\n",
      "52200\n",
      "52300\n",
      "52400\n",
      "52500\n",
      "52600\n",
      "52700\n",
      "52800\n",
      "52900\n",
      "53000\n",
      "53100\n",
      "53200\n",
      "53300\n",
      "53400\n",
      "53500\n",
      "53600\n",
      "53700\n",
      "53800\n",
      "53900\n",
      "54000\n",
      "54100\n",
      "54200\n",
      "54300\n",
      "54400\n",
      "54500\n",
      "54600\n",
      "54700\n",
      "54800\n",
      "54900\n",
      "55000\n",
      "55100\n",
      "55200\n",
      "55300\n",
      "55400\n"
     ]
    }
   ],
   "source": [
    "word_freq = Counter()\n",
    "df[\"text\"] = df[\"text\"].apply(tokenise_text, args = (word_freq,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we isolate the tokens which appear 3 times or fewer. They are mostly misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['awakeness',\n",
       " 'awakense',\n",
       " 'awaker',\n",
       " 'awakfulness',\n",
       " 'awakining',\n",
       " 'awakke',\n",
       " 'awakre',\n",
       " 'awakw',\n",
       " 'award',\n",
       " 'awarenes',\n",
       " 'awarranted',\n",
       " 'awave',\n",
       " 'awawre',\n",
       " 'aways',\n",
       " 'awb',\n",
       " 'awc',\n",
       " 'aweek',\n",
       " 'awell',\n",
       " 'aweyes',\n",
       " 'awf',\n",
       " 'awith',\n",
       " 'awkae',\n",
       " 'awke',\n",
       " 'awkoe',\n",
       " 'awkwardly',\n",
       " 'awlays',\n",
       " 'awmi',\n",
       " 'awning',\n",
       " 'awnsering',\n",
       " 'awopke',\n",
       " 'awwake',\n",
       " 'ax0',\n",
       " 'ax0x3',\n",
       " 'ax4',\n",
       " 'ax95',\n",
       " 'axacerbation',\n",
       " 'axallary',\n",
       " 'axatia',\n",
       " 'axcluded',\n",
       " 'axhypotension',\n",
       " 'axi',\n",
       " 'axialblood',\n",
       " 'axiallr',\n",
       " 'axiilary',\n",
       " 'axilalry',\n",
       " 'axillaries',\n",
       " 'axillarly',\n",
       " 'axillary04/29/12',\n",
       " 'axillaryadenopathy',\n",
       " 'axillas',\n",
       " 'axillia',\n",
       " 'axilliary',\n",
       " 'axilllary',\n",
       " 'axillobifem',\n",
       " 'axillofem',\n",
       " 'axillory',\n",
       " 'axilo',\n",
       " 'axious',\n",
       " 'axisand',\n",
       " 'axisdeviation',\n",
       " 'axithro',\n",
       " 'axithromycin',\n",
       " 'axium',\n",
       " 'axix',\n",
       " 'axlnd',\n",
       " 'axo3',\n",
       " 'axobifem',\n",
       " 'axol',\n",
       " 'axomal',\n",
       " 'axon',\n",
       " 'axones',\n",
       " 'axopt',\n",
       " 'axos',\n",
       " 'axox',\n",
       " 'axox0',\n",
       " 'axquired',\n",
       " 'axterixis',\n",
       " 'axtreonam',\n",
       " 'axx3',\n",
       " 'axycodone',\n",
       " 'aygestin',\n",
       " 'aygestrin',\n",
       " 'aymloidosis',\n",
       " 'aymmetric',\n",
       " 'aymtpomatic',\n",
       " 'ayoung',\n",
       " 'aypical',\n",
       " 'ayr',\n",
       " 'ays',\n",
       " 'aysmmetrical',\n",
       " 'aysmptommatic',\n",
       " 'aystole',\n",
       " 'aystolic',\n",
       " 'aystolle',\n",
       " 'aystomatic',\n",
       " 'aytropin',\n",
       " 'ayudar',\n",
       " 'az6474',\n",
       " 'azachol',\n",
       " 'azactam',\n",
       " 'azacytadine',\n",
       " 'azacytodine',\n",
       " 'azapt',\n",
       " 'azasan',\n",
       " 'azatadine',\n",
       " 'azathiaprine',\n",
       " 'azathiodine',\n",
       " 'azathiorpine',\n",
       " 'azathiporine',\n",
       " 'azathiprione',\n",
       " 'azathrioprine',\n",
       " 'azatioprine',\n",
       " 'azb',\n",
       " 'azd',\n",
       " 'azd2171',\n",
       " 'azd6474',\n",
       " 'aze',\n",
       " 'azecitadine',\n",
       " 'azentram',\n",
       " 'azeo',\n",
       " 'azetazolamide',\n",
       " 'azetemic',\n",
       " 'azetreonam',\n",
       " 'aziathromycin',\n",
       " 'azinamide',\n",
       " 'azintamide',\n",
       " 'azipramine',\n",
       " 'azirhtomycin',\n",
       " 'azitghromycin',\n",
       " 'azitha',\n",
       " 'azitho',\n",
       " 'azithor',\n",
       " 'azithormycin',\n",
       " 'azithrhomycin',\n",
       " 'azithroctx',\n",
       " 'azithrom',\n",
       " 'azithromcin',\n",
       " 'azithromicyn',\n",
       " 'azithromucin',\n",
       " 'azithromyci',\n",
       " 'azithromyciin',\n",
       " 'azithromycing',\n",
       " 'azithromyicin',\n",
       " 'azithromyin',\n",
       " 'azithromyzin',\n",
       " 'azithroycin',\n",
       " 'azithroymycin',\n",
       " 'azithryomycin',\n",
       " 'azithyromycin',\n",
       " 'azmarcort',\n",
       " 'azmocort',\n",
       " 'azntac',\n",
       " 'azocranberry',\n",
       " 'azocytadine',\n",
       " 'azofloxacin',\n",
       " 'azole',\n",
       " 'azoles',\n",
       " 'azolitmin',\n",
       " 'azootemia',\n",
       " 'azorean',\n",
       " 'azotemina',\n",
       " 'azothemia',\n",
       " 'azothiopram',\n",
       " 'azothioprim',\n",
       " 'azothiprine',\n",
       " 'azotreanam',\n",
       " 'azotrenam',\n",
       " 'azott',\n",
       " 'azreonam',\n",
       " 'azrteonam',\n",
       " 'aztereonem',\n",
       " 'azthioprin',\n",
       " 'azthmacort',\n",
       " 'azthromycin',\n",
       " 'aztreanam',\n",
       " 'aztrenam',\n",
       " 'aztrenoam',\n",
       " 'aztrenonam',\n",
       " 'aztreoman',\n",
       " 'aztreoname',\n",
       " 'aztreonan',\n",
       " 'aztreonma',\n",
       " 'aztreotam',\n",
       " 'aztronam',\n",
       " 'azucar',\n",
       " 'azygo',\n",
       " 'azygocaval',\n",
       " 'azyhtromycin',\n",
       " 'azythromax',\n",
       " 'azythromicin',\n",
       " 'azythroycin',\n",
       " 'azytrhomycin',\n",
       " 'azytromycin',\n",
       " 'b!2',\n",
       " \"b'l\",\n",
       " \"b'nai\",\n",
       " 'b0.1',\n",
       " 'b0.2',\n",
       " 'b0.4',\n",
       " 'b0.6',\n",
       " 'b0.9',\n",
       " 'b03/07/12',\n",
       " 'b1.1',\n",
       " 'b125',\n",
       " 'b12>1000',\n",
       " 'b12folate',\n",
       " 'b12s',\n",
       " 'b13',\n",
       " 'b1lood',\n",
       " 'b1pap',\n",
       " 'b2009',\n",
       " 'b21',\n",
       " 'b210',\n",
       " 'b2100',\n",
       " 'b22',\n",
       " 'b24',\n",
       " 'b25',\n",
       " 'b2glycoprotein',\n",
       " 'b2macroglobulin',\n",
       " 'b2microglob',\n",
       " 'b32',\n",
       " 'b325',\n",
       " 'b35',\n",
       " 'b3a',\n",
       " 'b41',\n",
       " 'b42',\n",
       " 'b44',\n",
       " 'b45',\n",
       " 'b5',\n",
       " 'b50',\n",
       " 'b5701',\n",
       " 'b58',\n",
       " 'b7',\n",
       " 'b76',\n",
       " 'b8',\n",
       " 'b82',\n",
       " 'b>1',\n",
       " 'b>2',\n",
       " 'b>2d',\n",
       " 'b>3',\n",
       " 'b>4',\n",
       " 'b>5.r',\n",
       " 'b>6',\n",
       " 'b>7',\n",
       " 'b><i',\n",
       " 'b??????hler',\n",
       " 'b]trace',\n",
       " 'baars',\n",
       " 'baastrup',\n",
       " 'baba',\n",
       " 'babble',\n",
       " 'babbled',\n",
       " 'babcock',\n",
       " 'babcocks',\n",
       " 'babesiamicroti',\n",
       " 'babesioses',\n",
       " 'babesisia',\n",
       " 'babesosis',\n",
       " 'babies',\n",
       " 'babinksis',\n",
       " 'babinkski',\n",
       " 'babinskie',\n",
       " 'babinskies',\n",
       " 'babinskin',\n",
       " 'babiski',\n",
       " 'babit',\n",
       " 'baboons',\n",
       " 'babsinki',\n",
       " 'babsinski',\n",
       " 'babysat',\n",
       " 'babysit',\n",
       " 'bacarbinate',\n",
       " 'bacaterial',\n",
       " 'bacatracin',\n",
       " 'baccale',\n",
       " 'baceam',\n",
       " 'baceria',\n",
       " 'bacerial',\n",
       " 'bacertial',\n",
       " 'baceteria',\n",
       " 'bacetermia',\n",
       " 'baci',\n",
       " 'bacid',\n",
       " 'bacili',\n",
       " 'bacilic',\n",
       " 'bacilus',\n",
       " 'bacitrac',\n",
       " 'bacitracint',\n",
       " 'bacitricin',\n",
       " 'back??????clearly',\n",
       " 'back\\\\',\n",
       " 'backaches',\n",
       " 'backand',\n",
       " 'backards',\n",
       " 'backawards',\n",
       " 'backback',\n",
       " 'backbaord',\n",
       " 'backbay',\n",
       " 'backbled',\n",
       " 'backboarded',\n",
       " 'backbones',\n",
       " 'backeards',\n",
       " 'backfill',\n",
       " 'backfills',\n",
       " 'backflashed',\n",
       " 'backflushing',\n",
       " 'backgeound',\n",
       " 'backgraound',\n",
       " 'backgroudn',\n",
       " 'backgroun',\n",
       " 'backgrounds',\n",
       " 'backgroundtowards',\n",
       " 'backgrounf\\\\d',\n",
       " 'backgroung',\n",
       " 'backhand',\n",
       " 'backj',\n",
       " 'backl',\n",
       " 'backout',\n",
       " 'backpacking',\n",
       " 'backpressure',\n",
       " 'backrgound',\n",
       " 'backround',\n",
       " 'backsurgery',\n",
       " 'backt',\n",
       " 'backtable',\n",
       " 'backwads',\n",
       " 'backwash',\n",
       " 'bacl',\n",
       " 'baclfen',\n",
       " 'baclk',\n",
       " 'baclofan',\n",
       " 'baclofin',\n",
       " 'baclomethanone',\n",
       " 'baclovent',\n",
       " 'bacod',\n",
       " 'bacroban',\n",
       " 'bacrtrim',\n",
       " 'bacse',\n",
       " 'bactaremia',\n",
       " 'bacteral',\n",
       " 'bactereia',\n",
       " 'bactereima',\n",
       " 'bacterej',\n",
       " 'bacteremeia',\n",
       " 'bacteremi',\n",
       " 'bacteremia_vre',\n",
       " 'bacteremiareferred',\n",
       " 'bacteremoa',\n",
       " 'bactereoides',\n",
       " 'bacteriacidal',\n",
       " 'bacteriae',\n",
       " 'bacterias',\n",
       " 'bacterical',\n",
       " 'bactericidal',\n",
       " 'bacterima',\n",
       " 'bacterimea',\n",
       " 'bacterimic',\n",
       " 'bacteriocidal',\n",
       " 'bacterioides',\n",
       " 'bacteriologic',\n",
       " 'bacteriologist',\n",
       " 'bacteriology',\n",
       " 'bactermeic',\n",
       " 'bactermemia',\n",
       " 'bactermias',\n",
       " 'bactermiea',\n",
       " 'bacteroids',\n",
       " 'bacteruia',\n",
       " 'bacteruira',\n",
       " 'bacteuria',\n",
       " 'bactfew',\n",
       " 'bactgrim',\n",
       " 'bacti',\n",
       " 'bactiera',\n",
       " 'bactirm',\n",
       " 'bactitracin',\n",
       " 'bactiuremia',\n",
       " 'bactmany',\n",
       " 'bactmod',\n",
       " 'bactocc',\n",
       " 'bactofen',\n",
       " 'bactraban',\n",
       " 'bactreal',\n",
       " 'bactreial',\n",
       " 'bactreim',\n",
       " 'bactreremia',\n",
       " 'bactrim400/80',\n",
       " 'bactrime',\n",
       " 'bactrin',\n",
       " 'bactriom',\n",
       " 'bactrm',\n",
       " 'bactrmia',\n",
       " 'bactrum',\n",
       " 'bacturemia',\n",
       " 'badder',\n",
       " 'badge',\n",
       " 'badger',\n",
       " 'badminton',\n",
       " 'badomen',\n",
       " 'bads',\n",
       " 'badycardic',\n",
       " 'baedp',\n",
       " 'baeen',\n",
       " 'baegan',\n",
       " 'baesline',\n",
       " 'baetablocker',\n",
       " 'baf',\n",
       " 'baffled',\n",
       " 'baffles',\n",
       " 'baffling',\n",
       " 'bagdasian',\n",
       " 'baged',\n",
       " 'bagels',\n",
       " 'baggeg',\n",
       " 'baggies',\n",
       " 'bagin',\n",
       " 'bagmask',\n",
       " 'bagx2',\n",
       " 'baharain',\n",
       " 'bahavioral',\n",
       " 'bahaviour',\n",
       " 'baidal',\n",
       " 'bailar',\n",
       " 'bailer',\n",
       " 'bainksi',\n",
       " 'baintree',\n",
       " 'baja',\n",
       " 'bakced',\n",
       " 'bakere',\n",
       " 'bakeries',\n",
       " 'bakes',\n",
       " 'balace',\n",
       " 'balane',\n",
       " 'balaned',\n",
       " 'balanoposthitis',\n",
       " 'balateral',\n",
       " 'balaterally',\n",
       " 'balboa',\n",
       " 'balckouts',\n",
       " 'balcofen',\n",
       " 'balcyte',\n",
       " 'baldbate',\n",
       " 'baldes',\n",
       " 'baldness',\n",
       " 'baldpate',\n",
       " 'bale',\n",
       " 'balence',\n",
       " 'bales',\n",
       " 'balganciclovir',\n",
       " 'baliff',\n",
       " 'balints',\n",
       " 'balk',\n",
       " 'balkan',\n",
       " 'balken',\n",
       " 'ballantitis',\n",
       " 'ballerina',\n",
       " 'ballgame',\n",
       " 'ballistic',\n",
       " 'ballloon',\n",
       " 'ballo9n',\n",
       " 'balloned',\n",
       " 'balloning',\n",
       " 'balloom',\n",
       " 'balloonangioplpasty',\n",
       " 'balloonometry',\n",
       " 'balloonvalvuloplasty',\n",
       " 'ballooon',\n",
       " 'ballowing',\n",
       " 'ballpark',\n",
       " 'ballpoint',\n",
       " 'balo',\n",
       " 'baloba',\n",
       " 'balofen',\n",
       " 'balontitis',\n",
       " 'balooned',\n",
       " 'balsa',\n",
       " 'balsalazine',\n",
       " 'balsalmic',\n",
       " 'balt',\n",
       " 'bamboo',\n",
       " 'bammock',\n",
       " 'banabag',\n",
       " 'banadage',\n",
       " 'banadaged',\n",
       " 'banadryl',\n",
       " 'bananabag',\n",
       " 'band18',\n",
       " 'bandagaed',\n",
       " 'bandaide',\n",
       " 'bandange',\n",
       " 'bandanged',\n",
       " 'bandemic',\n",
       " 'bandermia',\n",
       " 'bandiad',\n",
       " 'bands10',\n",
       " 'bands13',\n",
       " 'bands2',\n",
       " 'bands6',\n",
       " 'bandwagon',\n",
       " 'banemia',\n",
       " 'bangaed',\n",
       " 'bangages',\n",
       " 'bangaladesh',\n",
       " 'baninski',\n",
       " 'banister',\n",
       " 'banjo',\n",
       " 'banked',\n",
       " 'bankets',\n",
       " 'bankhart',\n",
       " 'banks',\n",
       " 'bankteller',\n",
       " 'banna',\n",
       " 'bannanas',\n",
       " 'banning',\n",
       " 'bannister',\n",
       " 'banovic',\n",
       " 'banquet',\n",
       " 'banquets',\n",
       " 'bans',\n",
       " 'bantering',\n",
       " 'banthine',\n",
       " 'bao',\n",
       " 'baody',\n",
       " 'baoust',\n",
       " 'baptise',\n",
       " 'baracat',\n",
       " 'baracath',\n",
       " 'baraim',\n",
       " 'barany',\n",
       " 'barba',\n",
       " 'barbae',\n",
       " 'barbaros',\n",
       " 'barbed',\n",
       " 'barbershop',\n",
       " 'barbitrpos',\n",
       " 'barbits',\n",
       " 'barcarbonate',\n",
       " 'barcelona',\n",
       " 'bardia',\n",
       " 'bardycardia',\n",
       " 'barefooted',\n",
       " 'barefot',\n",
       " 'barehugger',\n",
       " 'barematal',\n",
       " 'baretts',\n",
       " 'barewire',\n",
       " 'barfights',\n",
       " 'bargain',\n",
       " 'bargaining',\n",
       " 'bari',\n",
       " 'bariac',\n",
       " 'bariatic',\n",
       " 'baricaire',\n",
       " 'baricat',\n",
       " 'baricon',\n",
       " 'barier',\n",
       " 'barimaxx',\n",
       " 'barmitzvah',\n",
       " 'barnado',\n",
       " 'barnwood',\n",
       " 'barnyard',\n",
       " 'baroreceptor',\n",
       " 'baroreceptors',\n",
       " 'baroreflex',\n",
       " 'barorreceptor',\n",
       " 'barouk',\n",
       " 'barowner',\n",
       " 'barrack',\n",
       " 'barracks',\n",
       " 'barracuda',\n",
       " 'barraquer',\n",
       " 'barred',\n",
       " 'barrette',\n",
       " 'barrettes',\n",
       " 'barrettt',\n",
       " 'barricade',\n",
       " 'barricaded',\n",
       " 'barricades',\n",
       " 'barried',\n",
       " 'barrista',\n",
       " 'barshak',\n",
       " 'barstool',\n",
       " 'bartended',\n",
       " 'bartends',\n",
       " 'bartenella',\n",
       " 'bartholin??????s',\n",
       " 'bartholins',\n",
       " 'bartter',\n",
       " 'bas1.4',\n",
       " 'basa',\n",
       " 'basalateral',\n",
       " 'basalic',\n",
       " 'basalir',\n",
       " 'basalk',\n",
       " 'basalparenchymal',\n",
       " 'basaqd',\n",
       " 'bascilar',\n",
       " 'bascilic',\n",
       " 'basck',\n",
       " 'base>>r',\n",
       " 'baseal',\n",
       " 'basedon',\n",
       " 'baseement',\n",
       " 'basees',\n",
       " 'baseilne',\n",
       " 'basein',\n",
       " 'baseleine',\n",
       " 'baseliene',\n",
       " 'baselilne',\n",
       " 'baselime',\n",
       " 'baselined',\n",
       " 'baselinee',\n",
       " 'baselinehe',\n",
       " 'baselione',\n",
       " 'basese',\n",
       " 'basesline',\n",
       " 'basesm',\n",
       " 'basesr',\n",
       " 'basess',\n",
       " 'basetball',\n",
       " 'basex',\n",
       " 'basexs0',\n",
       " 'basexs2',\n",
       " 'basexs4',\n",
       " 'basia',\n",
       " 'basialr',\n",
       " 'basica',\n",
       " 'basics',\n",
       " 'basifrontal',\n",
       " 'basilare',\n",
       " 'basilarly',\n",
       " 'basilary',\n",
       " 'basilat',\n",
       " 'basiler',\n",
       " 'basiliar',\n",
       " 'basilica',\n",
       " 'basilix',\n",
       " 'basiliximab',\n",
       " 'basille',\n",
       " 'basinful',\n",
       " 'basins',\n",
       " 'basioccipital',\n",
       " 'basion',\n",
       " 'basiss',\n",
       " 'basist',\n",
       " 'bask',\n",
       " 'baslar',\n",
       " 'basleline',\n",
       " 'basliar',\n",
       " 'baslic',\n",
       " 'basliene',\n",
       " 'basment',\n",
       " 'baso0.3',\n",
       " 'basocervical',\n",
       " 'basocyte',\n",
       " 'basophilia',\n",
       " 'basoposterior',\n",
       " 'basosquamous',\n",
       " 'bass',\n",
       " 'bassal',\n",
       " 'bassam',\n",
       " 'basseline',\n",
       " 'bassilar',\n",
       " 'bassini',\n",
       " 'bassis',\n",
       " 'bassl',\n",
       " 'bassline',\n",
       " 'bast',\n",
       " 'basteroides',\n",
       " 'bastrim',\n",
       " 'batablockade',\n",
       " 'batal',\n",
       " 'batches',\n",
       " 'bated',\n",
       " 'bateria',\n",
       " 'baterial',\n",
       " 'bath2',\n",
       " 'batheroom',\n",
       " 'bathng',\n",
       " 'bathroon',\n",
       " 'bathrub',\n",
       " 'batihng',\n",
       " 'batime',\n",
       " 'batrim',\n",
       " 'batroom',\n",
       " 'bats',\n",
       " 'batswana',\n",
       " 'battalion',\n",
       " 'battelli',\n",
       " 'batter',\n",
       " 'batting',\n",
       " 'battled',\n",
       " 'battleships',\n",
       " 'baudy',\n",
       " 'baumanni',\n",
       " 'baummani',\n",
       " 'baummanni',\n",
       " 'bavaria',\n",
       " 'bave',\n",
       " 'bavonna',\n",
       " 'baxe',\n",
       " 'bayberry',\n",
       " 'bayoda',\n",
       " 'bayonet',\n",
       " 'bayoneting',\n",
       " 'baypoint',\n",
       " 'bayside',\n",
       " 'bayuda',\n",
       " 'baywood',\n",
       " 'baz',\n",
       " 'bazaar',\n",
       " 'bb12672',\n",
       " 'bb32',\n",
       " 'bballoon',\n",
       " 'bbas',\n",
       " 'bbba',\n",
       " 'bbe',\n",
       " 'bbffx',\n",
       " 'bbi',\n",
       " 'bbid',\n",
       " 'bbidmc',\n",
       " 'bbilateral',\n",
       " 'bbilaterally',\n",
       " 'bbit',\n",
       " 'bbl',\n",
       " 'bblk',\n",
       " 'bblobker',\n",
       " 'bblocer',\n",
       " 'bblocks',\n",
       " 'bblokade',\n",
       " 'bbloker',\n",
       " 'bblokers',\n",
       " 'bbow',\n",
       " 'bbp',\n",
       " 'bbpv',\n",
       " 'bbroken',\n",
       " 'bbronchoscopy',\n",
       " 'bbs',\n",
       " 'bbun',\n",
       " 'bbut',\n",
       " 'bbx',\n",
       " 'bby',\n",
       " 'bbypass',\n",
       " 'bc12',\n",
       " 'bcab',\n",
       " 'bcame',\n",
       " 'bcause',\n",
       " 'bcbs',\n",
       " 'bcca',\n",
       " 'bccs',\n",
       " 'bcd',\n",
       " 'bcil',\n",
       " 'bcl2x3',\n",
       " 'bcls',\n",
       " 'bcltx',\n",
       " 'bcnu',\n",
       " 'bcomplex',\n",
       " 'bcons',\n",
       " 'bcrs',\n",
       " 'bct',\n",
       " 'bcteremia',\n",
       " 'bcts',\n",
       " 'bcv',\n",
       " 'bcxrs',\n",
       " 'bcxx1',\n",
       " 'bd29',\n",
       " 'bday',\n",
       " 'bdeside',\n",
       " 'bdg',\n",
       " 'bdglucan',\n",
       " 'bdmc',\n",
       " 'bdominal',\n",
       " 'bdps',\n",
       " 'bdrm',\n",
       " 'bdy',\n",
       " 'beacame',\n",
       " 'beaches',\n",
       " 'beacme',\n",
       " 'beaconhill',\n",
       " 'beacuae',\n",
       " 'beacuase',\n",
       " 'beadside',\n",
       " 'beagles',\n",
       " 'beagn',\n",
       " 'beahviors',\n",
       " 'beaing',\n",
       " 'beairng',\n",
       " 'beaking',\n",
       " 'beame',\n",
       " 'beamed',\n",
       " 'beams',\n",
       " 'beandryl',\n",
       " 'beap',\n",
       " 'bearded',\n",
       " 'beared',\n",
       " 'bearhuger',\n",
       " 'beariing',\n",
       " 'bearin',\n",
       " 'bearly',\n",
       " 'bearth',\n",
       " 'bearting',\n",
       " 'beaseline',\n",
       " 'beases',\n",
       " 'beatblockers',\n",
       " 'beaters',\n",
       " 'beathing',\n",
       " 'beatin',\n",
       " 'beautiful',\n",
       " 'beb',\n",
       " 'bebefit',\n",
       " 'bebpr',\n",
       " 'bebridements',\n",
       " 'bebulin',\n",
       " 'becacizumab',\n",
       " 'becaise',\n",
       " 'becamae',\n",
       " 'becamce',\n",
       " 'becamde',\n",
       " 'becameanuric',\n",
       " 'becamed',\n",
       " 'becamen',\n",
       " 'becames',\n",
       " 'becamge',\n",
       " 'becaming',\n",
       " 'becamwse',\n",
       " 'becan',\n",
       " 'becaouse',\n",
       " 'becardiogenic',\n",
       " 'becareful',\n",
       " 'becase',\n",
       " 'becasme',\n",
       " 'becasuse',\n",
       " 'becauase',\n",
       " 'becaucse',\n",
       " 'becaues',\n",
       " 'becausae',\n",
       " 'becausea',\n",
       " 'becaused',\n",
       " 'becausing',\n",
       " 'becausme',\n",
       " 'becausr',\n",
       " 'becausue',\n",
       " 'beccame',\n",
       " 'beceame',\n",
       " 'becema',\n",
       " 'becertain',\n",
       " 'bechecked',\n",
       " 'bechol',\n",
       " 'becitracin',\n",
       " 'beclamethason',\n",
       " 'beclamthasone',\n",
       " 'beclomathasone',\n",
       " 'beclonase',\n",
       " 'beclouded',\n",
       " 'becloven',\n",
       " 'becoem',\n",
       " 'becomae',\n",
       " 'becomed',\n",
       " 'becomeing',\n",
       " 'becomese',\n",
       " 'becomign',\n",
       " 'becomine',\n",
       " 'becomoing',\n",
       " 'becompleted',\n",
       " 'beconaise',\n",
       " 'beconaze',\n",
       " 'beconming',\n",
       " 'beconsase',\n",
       " 'becqame',\n",
       " 'becske',\n",
       " 'becteremia',\n",
       " 'becteremic',\n",
       " 'becuae',\n",
       " 'becuause',\n",
       " 'bedalarm',\n",
       " 'bedamustine',\n",
       " 'bedand',\n",
       " 'bedatine',\n",
       " 'bedbug',\n",
       " 'bedclothing',\n",
       " 'bedding',\n",
       " 'bedframes',\n",
       " 'bedide',\n",
       " 'bedime',\n",
       " 'bedimte',\n",
       " 'bedischarged',\n",
       " 'bedise',\n",
       " 'bediside',\n",
       " 'bedning',\n",
       " 'bedoford',\n",
       " 'bedpain',\n",
       " 'bedpost',\n",
       " 'bedrails',\n",
       " 'bedroll',\n",
       " 'bedrooms',\n",
       " 'bedsdie',\n",
       " 'bedsearch',\n",
       " 'bedsheet',\n",
       " 'bedsidce',\n",
       " 'bedsided',\n",
       " 'bedsidetap',\n",
       " 'bedsise',\n",
       " 'bedsite',\n",
       " 'bedsore',\n",
       " 'bedsrest',\n",
       " 'bedswide',\n",
       " 'bedt',\n",
       " 'bedtimes',\n",
       " 'bedtine',\n",
       " 'bedtmie',\n",
       " 'bedweight',\n",
       " 'bedwetting',\n",
       " 'bedy',\n",
       " 'bee4n',\n",
       " 'beeb',\n",
       " 'beecause',\n",
       " 'beechwood',\n",
       " 'beeding',\n",
       " 'beelding',\n",
       " 'beelith',\n",
       " 'beenb',\n",
       " 'beencleared',\n",
       " 'beendizzy',\n",
       " 'beenexperiencing',\n",
       " 'beenexposed',\n",
       " 'beenin',\n",
       " 'beenon',\n",
       " 'beenprescribed',\n",
       " 'beenr',\n",
       " 'beenreceiving',\n",
       " 'beens',\n",
       " 'beenslightly',\n",
       " 'beenstarted',\n",
       " 'beenunsuccessful',\n",
       " 'beeped',\n",
       " 'beeping',\n",
       " 'beer8',\n",
       " 'beerworks',\n",
       " 'beestings',\n",
       " 'beeswax',\n",
       " 'beeter',\n",
       " 'beethum',\n",
       " 'beezel',\n",
       " 'befoe',\n",
       " 'befoer',\n",
       " 'befollowed',\n",
       " 'beforre',\n",
       " 'befre',\n",
       " 'befroe',\n",
       " 'befure',\n",
       " 'begam',\n",
       " 'begame',\n",
       " 'begane',\n",
       " 'beganing',\n",
       " 'begative',\n",
       " 'begatn',\n",
       " 'begcam',\n",
       " 'begfan',\n",
       " 'begged',\n",
       " 'begging',\n",
       " 'beggining',\n",
       " 'begign',\n",
       " 'beginging',\n",
       " 'begininning',\n",
       " 'beginners',\n",
       " 'beginnging',\n",
       " 'beginnig',\n",
       " 'beginnign',\n",
       " 'beginnng',\n",
       " 'beginnning',\n",
       " 'begisn',\n",
       " 'begna',\n",
       " 'begninning',\n",
       " 'begriming',\n",
       " 'begs',\n",
       " 'beguaic',\n",
       " 'begug',\n",
       " 'beh',\n",
       " 'beh??????et',\n",
       " 'behav',\n",
       " 'behavhior',\n",
       " 'behaviorally',\n",
       " 'behaviorial',\n",
       " 'behaviorist',\n",
       " 'behaviorly',\n",
       " 'behavios',\n",
       " 'behaviourly',\n",
       " 'behaviours',\n",
       " 'behaviror',\n",
       " 'behavoiral',\n",
       " 'behavoirs',\n",
       " 'behavoral',\n",
       " 'behavorial',\n",
       " 'behavour',\n",
       " 'behcets',\n",
       " 'beheld',\n",
       " 'behin',\n",
       " 'behooves',\n",
       " 'behvaior',\n",
       " 'behypoxemic']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infreq_words = [word for word in word_freq.keys() if word_freq[word] <= 3 and word[0].isdigit() == False]\n",
    "print(len(infreq_words))\n",
    "sorted(infreq_words)[10000:11000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try and see if we can correct the misspellings using the `pyspellchecker` library by using the Levenshtein Distance algorithm and comparing against a dictionary. We first add the words with >3 occurrence to our dictionary. This is because they include a lot of scientific/medical terms which might not already be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = [word for word in word_freq.keys() if word_freq[word] > 3]\n",
    "add_to_dictionary = \" \".join(freq_words)\n",
    "f=open(\"data/mimic_dict.txt\", \"w+\")\n",
    "f.write(add_to_dictionary)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "spell.distance = 1  # set the distance parameter to just 1 edit away - much quicker\n",
    "spell.word_frequency.load_text_file('data/mimic_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-50bc0c033612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmisspell_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisspelled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmisspell_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36mcorrection\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 str: The most likely candidate \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36mcandidates\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# get edit distance 1...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medit_distance_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36mknown\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    177\u001b[0m         return set(\n\u001b[1;32m    178\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_frequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_frequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         )\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m_check_if_should_check\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# check if it is a number (int, float, etc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "misspelled = spell.unknown(infreq_words)\n",
    "misspell_dict = {}\n",
    "for i, word in enumerate(misspelled):\n",
    "    if (word != spell.correction(word)):\n",
    "        misspell_dict[word] = spell.correction(word)\n",
    "    if (i % 100 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'withrawing': 'withdrawing',\n",
       " 'redistrubution': 'redistribution',\n",
       " 'silocone': 'silicone',\n",
       " '.s1': 's1',\n",
       " 'deterioate': 'deteriorate',\n",
       " 'hosptialzation': 'hospitalzation',\n",
       " 'coloc': 'colon',\n",
       " 'incidintally': 'incidentally',\n",
       " 'loprsesor': 'lopressor',\n",
       " 'doscontinued': 'discontinued',\n",
       " 'reitterated': 'reiterated',\n",
       " 'vancomycis': 'vancomycin',\n",
       " 'flumzenil': 'flumazenil',\n",
       " 'obsructions': 'obstructions',\n",
       " 'antipsychoitics': 'antipsychotics',\n",
       " 'mycfungin': 'micfungin',\n",
       " 'palpaltion': 'palpation',\n",
       " 'miinutes': 'minutes',\n",
       " 'congition': 'condition',\n",
       " 'pliva': 'oliva',\n",
       " 'paretal': 'parental',\n",
       " 'doxasozyn': 'doxasozin',\n",
       " 'stidy': 'study',\n",
       " 'ketalog': 'kenalog',\n",
       " 'changesa': 'changes',\n",
       " 'makung': 'making',\n",
       " 'pracentesis': 'parcentesis',\n",
       " 'brinchoscopies': 'bronchoscopies',\n",
       " 'overalli': 'overall',\n",
       " 'twingy': 'thingy',\n",
       " 'perninious': 'pernicious',\n",
       " 'succeptible': 'susceptible',\n",
       " 'pancreatit': 'pancreatic',\n",
       " 'abue': 'able',\n",
       " 'startedv': 'started',\n",
       " 'transalvular': 'transvalvular',\n",
       " 'retinoids': 'retinoid',\n",
       " 'secteion': 'section',\n",
       " 'becausue': 'because',\n",
       " 'clea': 'clear',\n",
       " 'membratnes': 'membranes',\n",
       " 'primaary': 'primary',\n",
       " 'exsanquination': 'exsanguination',\n",
       " 'inotropix': 'inotropic',\n",
       " 'difficluties': 'difficulties',\n",
       " 'ongestive': 'congestive',\n",
       " 'x49': '49',\n",
       " 'dysrhytmia': 'dysrhythmia',\n",
       " 'abdomenl': 'abdomen',\n",
       " 'discomofor': 'discomfor',\n",
       " 'alterally': 'laterally',\n",
       " 'dainage': 'drainage',\n",
       " 'firels': 'fires',\n",
       " 'requiriements': 'requirements',\n",
       " '.1yo': '41yo',\n",
       " 'aneur': 'neur',\n",
       " 'compred': 'compared',\n",
       " 'lowel': 'lower',\n",
       " 'differentioation': 'differentiation',\n",
       " 'wheeziing': 'wheezing',\n",
       " 'nrl': 'nil',\n",
       " 'aspiratiion': 'aspiration',\n",
       " 'oleukocytosis': 'leukocytosis',\n",
       " 'deemdd': 'deemed',\n",
       " 'hematopiesis': 'hematopoiesis',\n",
       " 'nortrirtyline': 'nortriptyline',\n",
       " 'rparasternal': 'parasternal',\n",
       " 'nosrils': 'nostrils',\n",
       " 'mvg': 'meg',\n",
       " 'humin': 'human',\n",
       " 'rhabdomylasis': 'rhabdomylosis',\n",
       " 'therapry': 'therapy',\n",
       " 'sulfasalaine': 'sulfasalazine',\n",
       " 'excalated': 'excavated',\n",
       " 'whicle': 'while',\n",
       " 'indtubated': 'intubated',\n",
       " 'intrtrochanteric': 'intertrochanteric',\n",
       " 'qya': 'ya',\n",
       " 'emedications': 'medications',\n",
       " 'platelats': 'platelets',\n",
       " 'subjecive': 'subjective',\n",
       " 'relationshp': 'relationship',\n",
       " 'rughly': 'roughly',\n",
       " 'wincester': 'winchester',\n",
       " 'endocscopies': 'endoscopies',\n",
       " 'monontirate': 'mononitrate',\n",
       " 'becasme': 'became',\n",
       " 'wweight': 'weight',\n",
       " 'faclity': 'facility',\n",
       " 'bdrm': 'brm',\n",
       " 'cyansosis': 'cyanosis',\n",
       " '.subtotal': 'subtotal',\n",
       " '.loud': 'loud',\n",
       " 'reinterrogtated': 'reinterrogated',\n",
       " 'desnies': 'denies',\n",
       " 'sh3e': 'she',\n",
       " 'prfound': 'profound',\n",
       " 'nonobstructibe': 'nonobstructive',\n",
       " 'taichi': 'tai chi',\n",
       " 'opinoin': 'opinion',\n",
       " 'natcotics': 'narcotics',\n",
       " 'demeclocylcline': 'demeclocycline',\n",
       " 'repletiong': 'repletion',\n",
       " 'ventericular': 'ventricular',\n",
       " 'phsyiologic': 'physiologic',\n",
       " '.popliteal': 'popliteal',\n",
       " 'fpund': 'found',\n",
       " 'stoo': 'too',\n",
       " 'edena': 'eden',\n",
       " 'suproglottic': 'supraglottic',\n",
       " 'utricaria': 'urticaria',\n",
       " 'requesition': 'requisition',\n",
       " 'protectioin': 'protection',\n",
       " 'atrioventicular': 'atrioventricular',\n",
       " 'excoration': 'excorations',\n",
       " 'levophe': 'levophen',\n",
       " 'syndergy': 'synergy',\n",
       " 'prophyalctically': 'prophylactically',\n",
       " 'infilatrative': 'infiltrative',\n",
       " 'acupella': 'acapella',\n",
       " 'perivavluvar': 'perivavluar',\n",
       " 'colected': 'collected',\n",
       " 'mathuen': 'methuen',\n",
       " 'brieflyl': 'briefly',\n",
       " 'sensoriom': 'sensorium',\n",
       " 'visua': 'visual',\n",
       " 'depolyment': 'deployment',\n",
       " 'confusionn': 'confusion',\n",
       " 'ischhemic': 'ischaemic',\n",
       " 'encaphalpathy': 'encephalpathy',\n",
       " 'thouough': 'thorough',\n",
       " 'perocedure': 'procedure',\n",
       " 'endose': 'endorse',\n",
       " 'intertrignous': 'intertriginous',\n",
       " 'gangarenous': 'gangrenous',\n",
       " 'spotchy': 'splotchy',\n",
       " 'lympohoblastic': 'lymphoblastic',\n",
       " 'p_q': 'pdq',\n",
       " 'humalopg': 'humalog',\n",
       " 'exoected': 'expected',\n",
       " 'fsailure': 'failure',\n",
       " 'ivsible': 'visible',\n",
       " 'vestoril': 'estoril',\n",
       " 'salmost': 'almost',\n",
       " 'hemdiaphragm': 'hemidiaphragm',\n",
       " 'rr50': 'r450',\n",
       " 'ganclyclovir': 'gancyclovir',\n",
       " 'esphageus': 'esphagus',\n",
       " 'siezed': 'seized',\n",
       " 'conversng': 'conversing',\n",
       " 'naladixic': 'nalidixic',\n",
       " 'disorienation': 'disorientation',\n",
       " 'hypereima': 'hyperemia',\n",
       " 'refferral': 'referral',\n",
       " 'attemptd': 'attempt',\n",
       " 'penumbral': 'penumbra',\n",
       " 'centere': 'centre',\n",
       " 'bidners': 'bidders',\n",
       " 'mgrc': 'marc',\n",
       " 'crabl': 'crawl',\n",
       " 'anjust': 'adjust',\n",
       " 'diereses': 'diureses',\n",
       " '.ivh': 'ivh',\n",
       " 'precuationsa': 'precuations',\n",
       " 'acros': 'across',\n",
       " 'supsequently': 'subsequently',\n",
       " 'involced': 'involved',\n",
       " 'cefotax': 'ceftax',\n",
       " 'operatiion': 'operation',\n",
       " 'ventiliatory': 'ventilatory',\n",
       " 'lymoh': 'lymph',\n",
       " 'ecovery': 'recovery',\n",
       " 'hemorrhae': 'hemorrhage',\n",
       " 'ebolization': 'embolization',\n",
       " 'notnt': 'nott',\n",
       " 'pading': 'paying',\n",
       " 'he3': 'he',\n",
       " 'menigiomas': 'meningiomas',\n",
       " 'cellecept': 'cellcept',\n",
       " 'hemolytica': 'hemolytic',\n",
       " 'profundly': 'profoundly',\n",
       " 'vourse': 'course',\n",
       " 'determinte': 'determine',\n",
       " 'throuughout': 'throughout',\n",
       " 'aount': 'amount',\n",
       " 'ueb': 'seb',\n",
       " 'cepahlosporin': 'cephalosporin',\n",
       " 'santostatin': 'sandostatin',\n",
       " 'myoglogin': 'myoglobin',\n",
       " 'dehydrations': 'dehydration',\n",
       " 'elsewehere': 'elsewhere',\n",
       " 'esophageus': 'esophagus',\n",
       " 'cureently': 'currently',\n",
       " 'aneurysmla': 'aneurysmal',\n",
       " 'radiololgy': 'radiology',\n",
       " 'tachycaardic': 'tachycardic',\n",
       " 'appotiments': 'appoitments',\n",
       " 'reharb': 'rehab',\n",
       " '.difficule': 'difficule',\n",
       " 'decomepensated': 'decompensated',\n",
       " 'elevo': 'elev',\n",
       " 'requirieng': 'requiring',\n",
       " 'throacotomy': 'thoracotomy',\n",
       " 'religously': 'religiously',\n",
       " 'parapneuomonic': 'parapneumonic',\n",
       " 'pp25': 'p125',\n",
       " 'possiboly': 'possibly',\n",
       " 'tachynpeic': 'tachypneic',\n",
       " 'transfusiosn': 'transfusion',\n",
       " 'hydrouretur': 'hydroureter',\n",
       " '.ers': 'hers',\n",
       " 'analegesics': 'analgesics',\n",
       " 'coginitive': 'cognitive',\n",
       " 'tachyarrhtymia': 'tachyarrhthmia',\n",
       " 'movemetns': 'movements',\n",
       " 'preheart': 'preheat',\n",
       " 'destat': 'desat',\n",
       " 'hypookinetic': 'hypokinetic',\n",
       " 'encterococcus': 'eneterococcus',\n",
       " 'ppeared': 'appeared',\n",
       " 'oolong': 'oblong',\n",
       " 'tongeu': 'tongue',\n",
       " 'possi': 'posi',\n",
       " 'aortio': 'aortic',\n",
       " 'burshing': 'bursting',\n",
       " 'biatrail': 'biatrial',\n",
       " 'suporb': 'superb',\n",
       " 'fstm': 'fsm',\n",
       " 'thios': 'this',\n",
       " 'flourescence': 'fluorescence',\n",
       " 'liocaine': 'lidocaine',\n",
       " 'cicrculation': 'circulation',\n",
       " 'granft': 'grant',\n",
       " \"ce'd\": 'ced',\n",
       " 'amikcain': 'amikacin',\n",
       " 'bractrim': 'bactrim',\n",
       " 'thouht': 'thought',\n",
       " 'anaphylactiod': 'anaphylactoid',\n",
       " 'mechanicallyu': 'mechanically',\n",
       " 'neuromma': 'neuroma',\n",
       " 't53': 'p53',\n",
       " 'catheterizsation': 'catheterisation',\n",
       " 'methylprednisoline': 'methylprednisolone',\n",
       " 'inverisons': 'inversions',\n",
       " 'tudies': 'studies',\n",
       " 'bleedind': 'bleeding',\n",
       " 'ewll': 'well',\n",
       " 'n64.1': '64.1',\n",
       " 'inituially': 'initially',\n",
       " 'intermedium': 'intermedius',\n",
       " 'brbb': 'brb',\n",
       " 'wone': 'one',\n",
       " 'metaplosia': 'metaplasia',\n",
       " 'hypoglycmeia': 'hypoglycemia',\n",
       " 'burketts': 'burkett',\n",
       " 'occurrenes': 'occurrences',\n",
       " 'jfa': 'fa',\n",
       " 'transfem': 'transfer',\n",
       " 'movemennt': 'movement',\n",
       " 'differtnial': 'differntial',\n",
       " 'phenytpoin': 'phenytoin',\n",
       " 'ashie': 'tashie',\n",
       " 'craushed': 'crashed',\n",
       " 'kbk': 'kb',\n",
       " 'hmangioma': 'hemangioma',\n",
       " \"k'cl\": 'kcl',\n",
       " 'regariding': 'regarding',\n",
       " 'retireed': 'retired',\n",
       " 'laxtulose': 'lactulose',\n",
       " 'representign': 'representing',\n",
       " 'chemothx': 'chemotx',\n",
       " 'continuacion': 'continuation',\n",
       " 'polyliner': 'polylinker',\n",
       " 'ketia': 'kezia',\n",
       " 'peptostreptococus': 'peptostreptococcus',\n",
       " 'meansured': 'measured',\n",
       " 'prevacic': 'prevacid',\n",
       " 'limpic': 'limpid',\n",
       " 'serviuce': 'service',\n",
       " 'adjasent': 'adjacent',\n",
       " 'x1/1': 'x11',\n",
       " 'necessay': 'necessary',\n",
       " 'administereed': 'administered',\n",
       " 'systeolic': 'systolic',\n",
       " 'decreascendo': 'decrescendo',\n",
       " 'restes': 'rested',\n",
       " 'pituitaty': 'pituitary',\n",
       " 'leukocytocis': 'leukocytosis',\n",
       " 'invaginaiton': 'invagination',\n",
       " 'ecgl': 'ecgd',\n",
       " 'actve': 'active',\n",
       " 'quivalent': 'equivalent',\n",
       " 'homens': 'homes',\n",
       " 'staaff': 'staff',\n",
       " 'timke': 'time',\n",
       " 'discontinuatin': 'discontinuation',\n",
       " 'glocosamine': 'glucosamine',\n",
       " 'yestrday': 'yesterday',\n",
       " 'segmement': 'segement',\n",
       " 'pupals': 'pupils',\n",
       " 'flumazinil': 'flumazenil',\n",
       " 'steroit': 'steroid',\n",
       " 'tapeer': 'taper',\n",
       " 'platetes': 'platets',\n",
       " 'cardioglist': 'cardiolgist',\n",
       " 'plantor': 'planter',\n",
       " 'erecently': 'recently',\n",
       " 'xtremities': 'extremities',\n",
       " 'conpletely': 'completely',\n",
       " 'conjunctval': 'conjunctival',\n",
       " 'dsticks': 'sticks',\n",
       " 'albs': 'alas',\n",
       " 'ingetions': 'ingestions',\n",
       " 'ctan': 'can',\n",
       " 'umbilicis': 'umbilicus',\n",
       " 'foremarms': 'forearms',\n",
       " 'rheumotology': 'rheumatology',\n",
       " 'blancket': 'blanket',\n",
       " 'gastra': 'astra',\n",
       " 'uneffective': 'ineffective',\n",
       " 'compartible': 'compatible',\n",
       " 'unactive': 'inactive',\n",
       " 'tangentail': 'tangential',\n",
       " 'preopd': 'preop',\n",
       " 'terminatned': 'terminated',\n",
       " '.shortly': 'shortly',\n",
       " 'signifcanct': 'signifcant',\n",
       " 'extensie': 'extensive',\n",
       " 'recanulize': 'recanalize',\n",
       " 'octagenarian': 'octogenarian',\n",
       " 'antidepresents': 'antidepressents',\n",
       " 'dysmeteria': 'dysmetria',\n",
       " 'deliriuim': 'delirium',\n",
       " 'apetitie': 'apetite',\n",
       " 'venouus': 'venous',\n",
       " 'cycolobenzaprine': 'cyclobenzaprine',\n",
       " 'permeabilitiy': 'permeability',\n",
       " 'wuith': 'with',\n",
       " 'ultmately': 'ultimately',\n",
       " 'biltateral': 'bilateral',\n",
       " 'reminade': 'remicade',\n",
       " '.cri': 'cri',\n",
       " '.appreciated': 'appreciated',\n",
       " 'recehecked': 'rechecked',\n",
       " 'femorral': 'femoral',\n",
       " 'cardioulgy': 'cardiolgy',\n",
       " 'roommated': 'roommate',\n",
       " 'emerically': 'emprically',\n",
       " 'ketoacidosos': 'ketoacidosis',\n",
       " 'comlete': 'complete',\n",
       " 'rbw': 'row',\n",
       " 'sitgmata': 'stigmata',\n",
       " 'medialize': 'medialized',\n",
       " 'antepardum': 'antepartum',\n",
       " 'asurgery': 'surgery',\n",
       " 'continuign': 'continuing',\n",
       " 'inpaitnet': 'inpaitent',\n",
       " 'amoiodarone': 'amiodarone',\n",
       " 'diruesing': 'diuresing',\n",
       " 'neopl': 'neops',\n",
       " 'rencke': 'hencke',\n",
       " 'transeferrred': 'transeferred',\n",
       " 'xt3': 'xt',\n",
       " 'stridoroud': 'stridorous',\n",
       " 'hypeglycemia': 'hypoglycemia',\n",
       " 'mestinol': 'mestinon',\n",
       " 'enteritiss': 'enteritis',\n",
       " 'q3n': 'q3',\n",
       " 'radious': 'radius',\n",
       " 'cister': 'sister',\n",
       " 'bblobker': 'bblocker',\n",
       " 'psycihatry': 'psychiatry',\n",
       " 'notender': 'nontender',\n",
       " 'adminisitration': 'administration',\n",
       " 'antitrypson': 'antitrypsin',\n",
       " 'girldfriend': 'girlfriend',\n",
       " 'initiallo': 'initially',\n",
       " 'explaoration': 'exploration',\n",
       " 'nrbi': 'nabi',\n",
       " 'nbg': 'ng',\n",
       " 'diffiile': 'difficle',\n",
       " 'deparatment': 'department',\n",
       " 'clarithromycine': 'clarithromycin',\n",
       " 'mvoe': 'move',\n",
       " 'nurtritional': 'nutritional',\n",
       " 'bronchoconstriciton': 'bronchoconstriction',\n",
       " 'leukcocytosis': 'leucocytosis',\n",
       " 'hr51': 'hr71',\n",
       " 'prastate': 'prostate',\n",
       " 'stimlation': 'stimulation',\n",
       " 'adecreased': 'decreased',\n",
       " 'sinigicant': 'signigicant',\n",
       " 'arounf': 'around',\n",
       " 'reseated': 'repeated',\n",
       " 'disconrtinued': 'discontinued',\n",
       " 'comtamination': 'contamination',\n",
       " 'gerontololgy': 'gerontology',\n",
       " 'diltiazemn': 'diltiazem',\n",
       " 'soa2': 'soap',\n",
       " 'pulss': 'pulse',\n",
       " 'chlorhexindine': 'chlorhexidine',\n",
       " 'inovlvement': 'involvement',\n",
       " 'pmiple': 'pimple',\n",
       " 'nitrglycerin': 'nitoglycerin',\n",
       " 'conncetions': 'connections',\n",
       " 'devolops': 'develops',\n",
       " 'desatturation': 'desaturation',\n",
       " 'sapehenous': 'saphenous',\n",
       " 'erythrolekemia': 'erythroleukemia',\n",
       " 'televison': 'television',\n",
       " 'diltezem': 'diltazem',\n",
       " 'hematololgy': 'hematology',\n",
       " 'asoiration': 'aspiration',\n",
       " 'broncioloalveolar': 'bronchioloalveolar',\n",
       " 'gaiac': 'gaia',\n",
       " 'sclerodactaly': 'sclerodactyly',\n",
       " 'complaings': 'complaints',\n",
       " 'downtirated': 'downtitrated',\n",
       " 'cardiolote': 'cardiolyte',\n",
       " 'rescusciated': 'resusciated',\n",
       " 'accouantant': 'accountant',\n",
       " 'ehtacrynic': 'ethacrynic',\n",
       " 'contiuing': 'continuing',\n",
       " 'ambualnce': 'ambulance',\n",
       " 'comparrison': 'comparison',\n",
       " 'st2': 'st',\n",
       " 'northease': 'northeast',\n",
       " 'aupple': 'apple',\n",
       " 'appointmwent': 'appointment',\n",
       " 'ectivity': 'activity',\n",
       " 'amliod': 'amiod',\n",
       " 'pimrose': 'primrose',\n",
       " 'icnsion': 'incsion',\n",
       " 'basion': 'basin',\n",
       " 'stepbrothers': 'stepbrother',\n",
       " 'medullar': 'medulla',\n",
       " 'asorbic': 'ascorbic',\n",
       " 'chemsitry': 'chemistry',\n",
       " 'nohting': 'nothing',\n",
       " 'lating': 'eating',\n",
       " 'soboe': 'oboe',\n",
       " 'mbl': 'ml',\n",
       " 'cliniically': 'clinically',\n",
       " 'resulatant': 'resultant',\n",
       " 'risbs': 'risks',\n",
       " 'visists': 'visits',\n",
       " 'hosptia': 'hosptial',\n",
       " 'eventaul': 'eventual',\n",
       " 'conmmunications': 'communications',\n",
       " 'poritons': 'portions',\n",
       " 'periumbilicar': 'periumbilical',\n",
       " 'chikld': 'child',\n",
       " 'injevtion': 'injection',\n",
       " 'follwowing': 'following',\n",
       " 'rescusiated': 'rescusitated',\n",
       " 'efexor': 'effexor',\n",
       " 'ac400': 'c400',\n",
       " 'empyma': 'empyema',\n",
       " 'x48y': 'x48',\n",
       " 'paxr': 'pair',\n",
       " 'boood': 'blood',\n",
       " 'qdhr': 'qhr',\n",
       " 'setiing': 'setting',\n",
       " 'soultion': 'solution',\n",
       " 'plasics': 'plastics',\n",
       " 'midazolm': 'midazolam',\n",
       " 'celss': 'cells',\n",
       " 'metazalone': 'metaxalone',\n",
       " 'henriation': 'herniation',\n",
       " 'nsgn': 'sgn',\n",
       " 'enocrinologist': 'endocrinologist',\n",
       " 'bronchscopic': 'bronchoscopic',\n",
       " 'abbd': 'abba',\n",
       " 'cordus': 'corpus',\n",
       " 'atnenolol': 'atenolol',\n",
       " 'imprssion': 'impression',\n",
       " 'sweelings': 'swellings',\n",
       " 'doxazosn': 'doxazosin',\n",
       " 'dysjunction': 'dysfunction',\n",
       " 'carbinate': 'carbonate',\n",
       " 'potral': 'portal',\n",
       " 'dropn': 'drop',\n",
       " 'percutanenous': 'percutaneous',\n",
       " 'ginerale': 'generale',\n",
       " 'qestioning': 'questioning',\n",
       " 'elecating': 'electing',\n",
       " 'k4.3': '54.3',\n",
       " 'brithday': 'birthday',\n",
       " 'resucsitated': 'resuscitated',\n",
       " 'patie3nt': 'patient',\n",
       " 'polysneuropathy': 'polyneuropathy',\n",
       " 'dehydrattion': 'dehydration',\n",
       " 'recurrenc': 'recurrent',\n",
       " 'lightheadesness': 'lightheadeness',\n",
       " 'dohl': 'doll',\n",
       " 'q120': '2120',\n",
       " 'desimpacted': 'disimpacted',\n",
       " 'furnucle': 'furuncle',\n",
       " 'minyx': 'minx',\n",
       " 'neuropthy': 'neuropathy',\n",
       " 'gounds': 'pounds',\n",
       " 'decied': 'decided',\n",
       " 'daunurubicin': 'daunorubicin',\n",
       " 'haoldol': 'haldol',\n",
       " 'snmall': 'small',\n",
       " 'revcently': 'recently',\n",
       " 'tlo': 'to',\n",
       " 'deniesy': 'denies',\n",
       " 'zalden': 'walden',\n",
       " 'moble': 'mobile',\n",
       " 'depressi': 'depress',\n",
       " 'rpofound': 'profound',\n",
       " 'intbuted': 'intubted',\n",
       " 'colonizaiton': 'colonization',\n",
       " 'flacky': 'flaky',\n",
       " 'diverticiulitis': 'diverticulitis',\n",
       " 'preferrence': 'preference',\n",
       " 'underlied': 'underlined',\n",
       " 'aspet': 'aspect',\n",
       " 'leukemea': 'leukemia',\n",
       " 'ventmask': 'ventimask',\n",
       " 'paltellar': 'patellar',\n",
       " 'dheydration': 'dehydration',\n",
       " 'allendronate': 'alendronate',\n",
       " 'julular': 'jugular',\n",
       " 'hytertensive': 'hypertensive',\n",
       " 'tranasaminitis': 'transaminitis',\n",
       " 'labd': 'land',\n",
       " 'erytema': 'erythema',\n",
       " 'eccetric': 'eccentric',\n",
       " 'overexpansion': 'over-expansion',\n",
       " 'anaphlactic': 'anaphylactic',\n",
       " \"movem't\": 'movemnt',\n",
       " 'omrs': 'mrs',\n",
       " 'loevnox': 'lovenox',\n",
       " 'faruncle': 'caruncle',\n",
       " 'moneth': 'month',\n",
       " 'fundoperinox': 'fundaperinox',\n",
       " '.aml': 'aml',\n",
       " 'sunclavian': 'subclavian',\n",
       " 'zofram4': 'zofram',\n",
       " 'repaced': 'replaced',\n",
       " 'trewatment': 'treatment',\n",
       " 'inurance': 'insurance',\n",
       " 'chamged': 'changed',\n",
       " 'zyr': 'ayr',\n",
       " 'oxytontin': 'oxycontin',\n",
       " 'casused': 'caused',\n",
       " 'diqoxin': 'dioxin',\n",
       " '.heroin': 'heroin',\n",
       " 'aua': 'aha',\n",
       " 'maduri': 'madura',\n",
       " 'uptitratring': 'uptitrating',\n",
       " 'decompensatoin': 'decompensation',\n",
       " 'rav': 'ran',\n",
       " 'housekekeping': 'housekeeping',\n",
       " 'sas2': 'sas',\n",
       " 'hemature': 'hematura',\n",
       " 'adequade': 'adequate',\n",
       " 't981.3': ' 981.3',\n",
       " 'destended': 'descended',\n",
       " 'ppressure': 'pressure',\n",
       " 'andan': 'andean',\n",
       " 'inonimate': 'inanimate',\n",
       " 'orgnaomegaly': 'organomegaly',\n",
       " 'hematochemia': 'hematochezia',\n",
       " 'stiagliptin': 'sitagliptin',\n",
       " '.prozac': 'prozac',\n",
       " 'compleatted': 'compleated',\n",
       " 'grade4': 'grade',\n",
       " 'csn': 'can',\n",
       " 'indivisually': 'individually',\n",
       " 'transmetataral': 'transmetatarsal',\n",
       " 'hydroxychloroqeuine': 'hydroxychloroquine',\n",
       " 'pbm': 'ibm',\n",
       " 'endopscopy': 'endoscopy',\n",
       " 'oxious': 'noxious',\n",
       " 'complaind': 'complained',\n",
       " 'bivenricular': 'biventricular',\n",
       " 'hospitlaziation': 'hospitlaization',\n",
       " 'ingect': 'insect',\n",
       " 'saamaritan': 'samaritan',\n",
       " 'clutre': 'cultre',\n",
       " 'finrillation': 'fibrillation',\n",
       " 'occure': 'occur',\n",
       " 'anticoagulatns': 'anticoagulants',\n",
       " 'dysfuntcion': 'dysfunction',\n",
       " 'naroowing': 'narrowing',\n",
       " 'gluteul': 'gluteal',\n",
       " 'oralpharygeal': 'oralpharyngeal',\n",
       " 'contrubutory': 'contributory',\n",
       " 'interatrialo': 'interatrial',\n",
       " 'ubilical': 'umbilical',\n",
       " 'hypventilation': 'hypoventilation',\n",
       " 'rohcester': 'rochester',\n",
       " 'paragoric': 'paregoric',\n",
       " 'fludricotisone': 'fludricortisone',\n",
       " 'ajacques': 'jacques',\n",
       " 'seizueres': 'seizures',\n",
       " 'persitsent': 'persistent',\n",
       " 'sojurn': 'sojourn',\n",
       " 'gentiourinary': 'genitourinary',\n",
       " 'sbp30s': 'sbp80s',\n",
       " 'cannualted': 'cannulated',\n",
       " 'waht': 'what',\n",
       " 'etting': 'getting',\n",
       " 'doxepim': 'doxepin',\n",
       " 'idepressed': 'depressed',\n",
       " 'discuassions': 'discussions',\n",
       " 'diluy': 'dilly',\n",
       " 'symmetriccal': 'symmetrical',\n",
       " 'outof': 'out of',\n",
       " 'indepedence': 'independence',\n",
       " 'labaratory': 'laboratory',\n",
       " 'drsssing': 'dressing',\n",
       " 'leteral': 'lateral',\n",
       " 'episone': 'episode',\n",
       " 'desaturaing': 'desaturating',\n",
       " 'minumal': 'minimal',\n",
       " 'bootster': 'booster',\n",
       " '/9': '9',\n",
       " 'laparosopy': 'laparoscopy',\n",
       " 'sclerotherpy': 'sclerotherapy',\n",
       " 'phlegman': 'phlegmon',\n",
       " 'fascile': 'facile',\n",
       " 'goddu': 'goddy',\n",
       " 'fluoros': 'fluoro',\n",
       " 'reyata': 'renata',\n",
       " 'decreated': 'decreased',\n",
       " 'cosopts': 'cosopt',\n",
       " 'capute': 'canute',\n",
       " 'pasages': 'passages',\n",
       " 'disipate': 'dissipate',\n",
       " 'biscodul': 'biscodyl',\n",
       " 'ulcear': 'ulcer',\n",
       " 'bronchoscopoy': 'bronchoscopy',\n",
       " 'rmained': 'remained',\n",
       " 'thjree': 'three',\n",
       " 'testall': 'westall',\n",
       " 'cpmr': 'pmr',\n",
       " 'diaphesis': 'diathesis',\n",
       " 'somnolene': 'somnolent',\n",
       " 'tramadole': 'tramadol',\n",
       " 'consulttion': 'consultation',\n",
       " 'moty': 'moth',\n",
       " 'phasia': 'aphasia',\n",
       " 'anyhting': 'anything',\n",
       " 'imcomplete': 'incomplete',\n",
       " 'inicluding': 'including',\n",
       " 'sutres': 'sutures',\n",
       " 'cefetazidime': 'ceftazidime',\n",
       " 'adgitation': 'agitation',\n",
       " 'bs13': 's13',\n",
       " 't105.8': '9105.8',\n",
       " 'seeeding': 'speeding',\n",
       " 'amiodarome': 'amiodarone',\n",
       " 'arrivede': 'arrived',\n",
       " 'graftinf': 'grafting',\n",
       " 'jahovah': 'jehovah',\n",
       " 'sgone': 'gone',\n",
       " 'arelatively': 'relatively',\n",
       " 'proporanolol': 'propranolol',\n",
       " 'transaminititis': 'transaminitits',\n",
       " 'righth': 'right',\n",
       " 'hyokalemia': 'hypokalemia',\n",
       " 'bloched': 'blocked',\n",
       " 'radiaion': 'radiation',\n",
       " 'func': 'fund',\n",
       " 'entake': 'intake',\n",
       " 'oreitned': 'oreinted',\n",
       " 'inhailor': 'inhalor',\n",
       " 'sodiium': 'sodium',\n",
       " 'setttings': 'settings',\n",
       " 'recods': 'records',\n",
       " 'resealing': 'revealing',\n",
       " 'nephrostoly': 'nephrostomy',\n",
       " 'hempdynamically': 'hemodynamically',\n",
       " 'rectently': 'recently',\n",
       " '.benadryl': 'benadryl',\n",
       " 'blaoting': 'blasting',\n",
       " 'joits': 'joints',\n",
       " 'faciliation': 'facilitation',\n",
       " 'forteen': 'fourteen',\n",
       " 'propxy': 'proxy',\n",
       " 'denatal': 'dental',\n",
       " 'teaspooon': 'teaspoon',\n",
       " 'isolcation': 'isolation',\n",
       " 'exacerabations': 'exacerbations',\n",
       " 'magnesiua': 'magnesium',\n",
       " 'bumetinide': 'bumetanide',\n",
       " 'herseld': 'herself',\n",
       " '.ercp': 'ercp',\n",
       " 'phenominon': 'phenomenon',\n",
       " 'respnded': 'responded',\n",
       " 'pleuradecis': 'pleuradesis',\n",
       " 'diated': 'dated',\n",
       " 'civa': 'cia',\n",
       " 'communitu': 'community',\n",
       " 'gandida': 'candida',\n",
       " 'xallegra': 'allegra',\n",
       " 'asna': 'asia',\n",
       " 'stasrted': 'started',\n",
       " 'immunosppression': 'immunosuppression',\n",
       " 'chlorhexidone': 'chlorhexidine',\n",
       " 'hypopharangeal': 'hypopharyngeal',\n",
       " 'mesiscus': 'meniscus',\n",
       " 'normodephalic': 'normocephalic',\n",
       " 'resectino': 'resection',\n",
       " 'psin': 'pain',\n",
       " 'mmode': 'mode',\n",
       " 'iunflow': 'inflow',\n",
       " 'egions': 'regions',\n",
       " 'antrial': 'antral',\n",
       " 'theraupetic': 'therapuetic',\n",
       " 'managemtnt': 'management',\n",
       " 'evental': 'eventual',\n",
       " 'ihistory': 'history',\n",
       " 'depenedent': 'dependent',\n",
       " 'flucutates': 'fluctuates',\n",
       " 'diagaonal': 'diagonal',\n",
       " 'auscualtion': 'ausculation',\n",
       " 'serosangunous': 'serosangenous',\n",
       " 'visularized': 'visulalized',\n",
       " 'sucralfat': 'sucralfate',\n",
       " 'pseudomeningogele': 'pseudomeningocele',\n",
       " 'phenegren': 'phenergen',\n",
       " 'consideratin': 'consideration',\n",
       " 'hyromegaly': 'thyromegaly',\n",
       " 'rept': 'rest',\n",
       " 'crmmf': 'crmf',\n",
       " 'wheezieng': 'wheezing',\n",
       " 'dhart': 'chart',\n",
       " 'emcitabine': 'gemcitabine',\n",
       " 'myloglobin': 'myoglobin',\n",
       " 'impipramine': 'imipramine',\n",
       " 'defieciency': 'deficiency',\n",
       " 'exreted': 'exerted',\n",
       " 'mwth': 'myth',\n",
       " 'utterence': 'utterance',\n",
       " 'disccusion': 'discusion',\n",
       " 'reclination': 'declination',\n",
       " 'moblization': 'mobilization',\n",
       " 'intermittnatly': 'intermittnetly',\n",
       " 'dorazolamide': 'dorzolamide',\n",
       " 'precords': 'records',\n",
       " 'foranen': 'foramen',\n",
       " 'disseas': 'diseas',\n",
       " 'gastropahty': 'gastropathy',\n",
       " 'emmesis': 'ememsis',\n",
       " 'alphigan': 'alphagan',\n",
       " 'ryhtym': 'rythym',\n",
       " 'rlle': 'role',\n",
       " 'haperin': 'heperin',\n",
       " 'hypoxias': 'hypoxia',\n",
       " 'echnogenic': 'echogenic',\n",
       " 'rimfampin': 'rifampin',\n",
       " 'etioogy': 'etiology',\n",
       " 'shellfhish': 'shellfish',\n",
       " 'superviser': 'supervisor',\n",
       " '.hypoenhancing': 'hypoenhancing',\n",
       " 'telangietasias': 'telangiectasias',\n",
       " 'bleeded': 'blended',\n",
       " 'deemend': 'deemed',\n",
       " 'hemiclip': 'hemoclip',\n",
       " 'extuibated': 'extuabated',\n",
       " 'kilobyte': 'kilobytes',\n",
       " 'retuxan': 'rituxan',\n",
       " 'carboplatinium': 'carboplatinum',\n",
       " 'recussication': 'recussitation',\n",
       " 'lansoparazole': 'lansoprazole',\n",
       " 'insulim': 'insulin',\n",
       " 'dictaion': 'dictation',\n",
       " 'vermial': 'vermal',\n",
       " 'q6mos': '6mos',\n",
       " 'rtedly': 'redly',\n",
       " 't3n1n0': 't3n1m0',\n",
       " 'moitor': 'motor',\n",
       " 'aoccluded': 'occluded',\n",
       " 'lymphangenic': 'lymphangetic',\n",
       " 'yete': 'yet',\n",
       " 'defficits': 'deficits',\n",
       " 'posteriorely': 'posteriorly',\n",
       " 'dourse': 'course',\n",
       " 'neceassary': 'necessary',\n",
       " 'dauly': 'daily',\n",
       " 'educationr': 'education',\n",
       " 'sapenous': 'saphenous',\n",
       " 'pseudocout': 'pseudogout',\n",
       " 'fleuroscopy': 'fluroscopy',\n",
       " 'hematocrir': 'hematocrit',\n",
       " 'encaphalopathic': 'encephalopathic',\n",
       " 'leschol': 'lescol',\n",
       " 'pegsasys': 'pegasys',\n",
       " 'focues': 'focus',\n",
       " 'llf': 'elf',\n",
       " 'samaratan': 'samaritan',\n",
       " 'intable': 'inable',\n",
       " 'bloomguard': 'bloomgard',\n",
       " 'thickeneing': 'thickening',\n",
       " 'brance': 'france',\n",
       " 'synptoms': 'symptoms',\n",
       " 'funcioning': 'functioning',\n",
       " 'drainaeg': 'drainage',\n",
       " 'bicepc': 'biceps',\n",
       " 'adusted': 'adjusted',\n",
       " 'tgen': 'then',\n",
       " 'subsequentlt': 'subsequently',\n",
       " 'espcially': 'especially',\n",
       " 'evalautred': 'evalauted',\n",
       " 'slurrring': 'slurring',\n",
       " 'statments': 'statements',\n",
       " 'disloging': 'dislodging',\n",
       " 'involv': 'involve',\n",
       " 'iseptal': 'septal',\n",
       " 'debibrillation': 'defibrillation',\n",
       " 'apatient': 'patient',\n",
       " 'letely': 'lately',\n",
       " 'anigoraphy': 'angigoraphy',\n",
       " 'contreat': 'contrat',\n",
       " 'deicison': 'decison',\n",
       " 'bimatopropst': 'bimatoprost',\n",
       " 'chronoc': 'chronic',\n",
       " 'ommunophenotypic': 'immunophenotypic',\n",
       " 'readyu': 'ready',\n",
       " 'irirr': 'iirr',\n",
       " 'specilaties': 'specialties',\n",
       " 'thiin': 'thin',\n",
       " 'manipulted': 'manipulated',\n",
       " 'rheumtologic': 'rheumatologic',\n",
       " 'combniation': 'combination',\n",
       " 'movemens': 'movement',\n",
       " 'hypnonatremia': 'hyponatremia',\n",
       " 'gluocnate': 'gluconate',\n",
       " 'recevie': 'receive',\n",
       " 'nordstroms': 'nordstrom',\n",
       " 'x+1': 'x1',\n",
       " 'flucutuated': 'fluctuated',\n",
       " 'hyperative': 'hyperactive',\n",
       " 'paravalar': 'paravalvar',\n",
       " 'gassey': 'massey',\n",
       " 'addendun': 'addendum',\n",
       " 'sucecwssful': 'sucecssful',\n",
       " 'tobramicin': 'tobramycin',\n",
       " 'a?b': 'ab',\n",
       " 'prcedex': 'precedex',\n",
       " 'fasciotomoy': 'fasciotomy',\n",
       " 'ppropranolol': 'propranolol',\n",
       " 'inferrolateral': 'inferolateral',\n",
       " 'criticaide': 'criticaid',\n",
       " 'eschlerichia': 'escherichia',\n",
       " 'pretreatement': 'pretreatment',\n",
       " 'aganst': 'against',\n",
       " 'osteonectosis': 'osteonecrosis',\n",
       " 'azythromax': 'azithromax',\n",
       " 'atovoquon': 'atovoquone',\n",
       " 'epicaridium': 'epicardium',\n",
       " 'followiung': 'following',\n",
       " 'lueni': 'leni',\n",
       " 'frrling': 'furling',\n",
       " 'cheonic': 'chronic',\n",
       " 'jacues': 'jacques',\n",
       " 'perhicholecystic': 'pericholecystic',\n",
       " 'embolisatio': 'embolisation',\n",
       " 'triglycierides': 'triglycerides',\n",
       " 'obtai': 'obtain',\n",
       " 'seconardary': 'seconadary',\n",
       " 'tickel': 'ticket',\n",
       " 'piquids': 'liquids',\n",
       " 'cellucept': 'cellcept',\n",
       " 'extremus': 'extremes',\n",
       " 'smocking': 'smoking',\n",
       " 'ppd4': 'ppd',\n",
       " 'abomden': 'abodmen',\n",
       " 'arifact': 'artifact',\n",
       " 'pm0': 'pm',\n",
       " 'hemipalegic': 'hemiplegic',\n",
       " 'deiviated': 'deviated',\n",
       " 'electrophresis': 'electrophoresis',\n",
       " 'gaugue': 'gauge',\n",
       " 'calcfications': 'calcifications',\n",
       " 'factord': 'factors',\n",
       " 'commants': 'comments',\n",
       " '.things': 'things',\n",
       " 'trauamatic': 'traumatic',\n",
       " 'dpine': 'pine',\n",
       " 'akietic': 'akinetic',\n",
       " 'opacitities': 'opactities',\n",
       " 'stairts': 'starts',\n",
       " 'wadwa': 'wada',\n",
       " 'cylothorax': 'chylothorax',\n",
       " 'shortenting': 'shortening',\n",
       " 'meninogococcal': 'meningococcal',\n",
       " 'inturated': 'intubated',\n",
       " 'ultimitely': 'ultimately',\n",
       " 'recieivign': 'recieiving',\n",
       " 'azithromyzin': 'azithromycin',\n",
       " 'thouight': 'thought',\n",
       " 'extropia': 'exotropia',\n",
       " 'insertiion': 'insertion',\n",
       " 'disciussion': 'discussion',\n",
       " 'alcoho': 'alcohol',\n",
       " 'vts600': 'vt600',\n",
       " 'parencnymal': 'parenchymal',\n",
       " 'felkt': 'felt',\n",
       " 'comoplicated': 'complicated',\n",
       " 'chloramphenocol': 'chloramphenicol',\n",
       " 'brusises': 'bruises',\n",
       " 'hydropeumothorax': 'hydropneumothorax',\n",
       " 'demonsrtated': 'demonstrated',\n",
       " 'prommpting': 'prompting',\n",
       " 'amisp': 'amiss',\n",
       " 'gastrppathy': 'gastropathy',\n",
       " 'perfomring': 'performing',\n",
       " 'facine': 'facing',\n",
       " 'sbrs': 'sprs',\n",
       " 'uunclear': 'unclear',\n",
       " 'becoem': 'become',\n",
       " 'sliiping': 'slipping',\n",
       " 'breas': 'areas',\n",
       " 'scratcher': 'scratched',\n",
       " 'diphenhidramine': 'diphenhydramine',\n",
       " 'ultimatium': 'ultimatum',\n",
       " 'cinically': 'clinically',\n",
       " 'ncaer': 'caer',\n",
       " 'fospheynytoin': 'fosphenytoin',\n",
       " 'opthhalmicus': 'ophthalmicus',\n",
       " 'inarguably': 'unarguably',\n",
       " 'initiail': 'initial',\n",
       " 'artertiotomy': 'arteriotomy',\n",
       " 'ul18': 'u18',\n",
       " 'ducusate': 'docusate',\n",
       " 'nurition': 'nutrition',\n",
       " 'eother': 'other',\n",
       " 'rsspy': 'raspy',\n",
       " 'narocotic': 'narcotic',\n",
       " 'tty': 'try',\n",
       " 'reasctive': 'reactive',\n",
       " 'blaching': 'bleaching',\n",
       " 'interms': 'interims',\n",
       " 'americal': 'american',\n",
       " 'addmisison': 'addmission',\n",
       " 'pansenstitive': 'pansensitive',\n",
       " 'dilauaid': 'dilaudid',\n",
       " 'perococt': 'perocoet',\n",
       " 'pobably': 'probably',\n",
       " 'promimal': 'proximal',\n",
       " 'c2d3': 'cd3',\n",
       " 'soom': 'room',\n",
       " 'lealed': 'leaned',\n",
       " 'prednisonde': 'prednisone',\n",
       " 'hydrophila': 'hygrophila',\n",
       " 'meningitidus': 'meningitides',\n",
       " 'llving': 'living',\n",
       " 'fluctutating': 'fluctuating',\n",
       " 'receiprocal': 'reciprocal',\n",
       " 'prccedure': 'procedure',\n",
       " 'wokr': 'work',\n",
       " 'procees': 'process',\n",
       " 'rehabilitataion': 'rehabilitation',\n",
       " 'fibroses': 'fibrosis',\n",
       " 'quadruceps': 'quadriceps',\n",
       " 'diagnpsing': 'diagnosing',\n",
       " 'ct31': 'cd31',\n",
       " 'prodcess': 'process',\n",
       " 'reinstiution': 'reinstitution',\n",
       " 'illicitied': 'illicited',\n",
       " 'infundibulums': 'infundibulum',\n",
       " 'zosyna': 'zosyn',\n",
       " 'cirrhoss': 'cirrhosis',\n",
       " 'arrousability': 'arousability',\n",
       " 'unremarkanble': 'unremarkable',\n",
       " 'hemicrainectomy': 'hemicraniectomy',\n",
       " '.activity': 'activity',\n",
       " 'foujnd': 'found',\n",
       " 'ventriculat': 'ventricular',\n",
       " 'ehlichia': 'erhlichia',\n",
       " 'zygomas': 'zygoma',\n",
       " 'arranage': 'arrange',\n",
       " 'sideway': 'sideways',\n",
       " 'pz': 'p.',\n",
       " 'angion': 'anion',\n",
       " 'secu': 'sec',\n",
       " 'proivders': 'providers',\n",
       " 'faciliating': 'facilitating',\n",
       " 'resultys': 'results',\n",
       " 'hemodynaomically': 'hemodynamically',\n",
       " 'leviva': 'lexiva',\n",
       " 'pscyhiatris': 'pscyhiatric',\n",
       " 'herudin': 'hirudin',\n",
       " 'na159': 'na139',\n",
       " 'coloered': 'coloured',\n",
       " 'streprococcus': 'streptococcus',\n",
       " 'andterioseptal': 'anterioseptal',\n",
       " 'thrombovytopenia': 'thrombocytopenia',\n",
       " 'fulticasone': 'fluticasone',\n",
       " 'seervice': 'service',\n",
       " 'cftazidime': 'ceftazidime',\n",
       " 'gasrointestinal': 'gastrointestinal',\n",
       " 'eqivocal': 'equivocal',\n",
       " 'sphinctorotomy': 'sphincterotomy',\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(misspell_dict))\n",
    "misspell_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have correct spellings for many words in our dictionary that occurred <= 3 times. Anything else will be marked as `UNK`. We will save these as text files to avoid having to run this computation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f6a569859603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munk_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfreq_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisspell_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munk_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f6a569859603>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munk_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfreq_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisspell_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munk_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unk_words = [word for word in infreq_words if word not in list(misspell_dict.keys())]\n",
    "len(unk_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'treatement' in misspell_dict.keys():\n",
    "    print (misspell_dict['treatement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/discharge_unk_words.txt', unk_words, fmt='%s', newline=os.linesep)\n",
    "f=open(\"data/discharge_typos.txt\", \"w+\")\n",
    "\n",
    "for key in misspell_dict:\n",
    "    f.write(key + '\\t' + misspell_dict[key] + '\\n')\n",
    "f.close()\n",
    "\n",
    "#pd.read_csv('data/discharge_typos.txt', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will correct spelling mistakes whilst any word left uncorrected will be replaced with `<UNK>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_typos(text, typos, unks):\n",
    "    \n",
    "    tokens = text.split()\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token.lower() in typos.keys():\n",
    "            token = typos[token.lower()]\n",
    "        elif token.lower() in unks:\n",
    "            token = \"<UNK>\"\n",
    "        tokenised_text = tokenised_text + token + \" \"\n",
    "    \n",
    "    return tokenised_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenising function elementwise\n",
    "df[\"text\"] = df[\"text\"].apply(fix_typos, args = (misspell_dict, unk_words))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(df.head()['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text field has now been fully cleaned and tokenised. We can proceed to extract the first few tokens to use as a hint and move forth with joining other tables and partitioning the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "(55404, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "      <th>hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>145834</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2101-10-31</td>\n",
       "      <td>44005</td>\n",
       "      <td>77</td>\n",
       "      <td>Admission Date : [ 2101/10/20 ] Discharge Date...</td>\n",
       "      <td>Admission Date : [ 2101/10/20 ] Discharge Date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2143-05-12</td>\n",
       "      <td>F</td>\n",
       "      <td>185777</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2191-03-23</td>\n",
       "      <td>4788</td>\n",
       "      <td>48</td>\n",
       "      <td>Admission Date : [ 2191/3/16 ] Discharge Date ...</td>\n",
       "      <td>Admission Date : [ 2191/3/16 ] Discharge Date : [</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2109-06-21</td>\n",
       "      <td>F</td>\n",
       "      <td>107064</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2175-06-15</td>\n",
       "      <td>20825</td>\n",
       "      <td>66</td>\n",
       "      <td>Admission Date : [ 2175/5/30 ] Discharge Date ...</td>\n",
       "      <td>Admission Date : [ 2175/5/30 ] Discharge Date : [</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>57115</td>\n",
       "      <td>42</td>\n",
       "      <td>Name : [ Known lastname 10050 ] , [ Known firs...</td>\n",
       "      <td>Name : [ Known lastname 10050 ] , [ Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-13</td>\n",
       "      <td>20070</td>\n",
       "      <td>42</td>\n",
       "      <td>Admission Date : [ 2149/11/9 ] Discharge Date ...</td>\n",
       "      <td>Admission Date : [ 2149/11/9 ] Discharge Date : [</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender  hadm_id           category  chartdate  \\\n",
       "0           3 2025-04-11      M   145834  Discharge summary 2101-10-31   \n",
       "1           4 2143-05-12      F   185777  Discharge summary 2191-03-23   \n",
       "2           6 2109-06-21      F   107064  Discharge summary 2175-06-15   \n",
       "3           9 2108-01-26      M   150750  Discharge summary 2149-11-14   \n",
       "4           9 2108-01-26      M   150750  Discharge summary 2149-11-13   \n",
       "\n",
       "   row_id  age_at_noteevent  \\\n",
       "0   44005                77   \n",
       "1    4788                48   \n",
       "2   20825                66   \n",
       "3   57115                42   \n",
       "4   20070                42   \n",
       "\n",
       "                                                text  \\\n",
       "0  Admission Date : [ 2101/10/20 ] Discharge Date...   \n",
       "1  Admission Date : [ 2191/3/16 ] Discharge Date ...   \n",
       "2  Admission Date : [ 2175/5/30 ] Discharge Date ...   \n",
       "3  Name : [ Known lastname 10050 ] , [ Known firs...   \n",
       "4  Admission Date : [ 2149/11/9 ] Discharge Date ...   \n",
       "\n",
       "                                                hint  \n",
       "0  Admission Date : [ 2101/10/20 ] Discharge Date...  \n",
       "1  Admission Date : [ 2191/3/16 ] Discharge Date : [  \n",
       "2  Admission Date : [ 2175/5/30 ] Discharge Date : [  \n",
       "3          Name : [ Known lastname 10050 ] , [ Known  \n",
       "4  Admission Date : [ 2149/11/9 ] Discharge Date : [  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "def produce_hint(text):\n",
    "    global counter\n",
    "    l = text.split()\n",
    "    counter += 1\n",
    "    if (counter % 10000) == 0:\n",
    "        print (counter)\n",
    "    return ' '.join(l[:10]) # first 10 tokens\n",
    "\n",
    "df['hint'] = df['text'].map(lambda x: produce_hint(x))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients above 89 years of age had their dob modified to be 300 years old at time of first event for privacy reasons\n",
    "# change their age to instead be 90\n",
    "\n",
    "df.loc[df['age_at_noteevent'] > 200, 'age_at_noteevent'] = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "      <td>Atypical Lymphocytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "      <td>Bands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "      <td>Basophils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "      <td>Eosinophils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>%</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Hematocrit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id           charttime value valueuom      flag  \\\n",
       "0           2 2138-07-17 20:48:00     0        %      None   \n",
       "1           2 2138-07-17 20:48:00     0        %      None   \n",
       "2           2 2138-07-17 20:48:00     0        %      None   \n",
       "3           2 2138-07-17 20:48:00     0        %      None   \n",
       "4           2 2138-07-17 20:48:00     0        %  abnormal   \n",
       "\n",
       "                  label  \n",
       "0  Atypical Lymphocytes  \n",
       "1                 Bands  \n",
       "2             Basophils  \n",
       "3           Eosinophils  \n",
       "4            Hematocrit  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lab items data\n",
    "\n",
    "df_labitems = pd.read_sql_query('''\n",
    "  SELECT l.subject_id, l.charttime, l.value, l.valueuom, l.flag, d.label\n",
    "  FROM labevents l\n",
    "  INNER JOIN d_labitems d \n",
    "  USING (itemid)\n",
    "  ORDER BY l.subject_id\n",
    "  LIMIT 10000;\n",
    "''', cnx)\n",
    "\n",
    "print(df_labitems.shape)\n",
    "df_labitems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>drug</th>\n",
       "      <th>prod_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-18</td>\n",
       "      <td>2138-07-20</td>\n",
       "      <td>NEO*IV*Gentamicin</td>\n",
       "      <td>10mg/mL-2mL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-18</td>\n",
       "      <td>2138-07-21</td>\n",
       "      <td>Ampicillin Sodium</td>\n",
       "      <td>500mg Vial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-18</td>\n",
       "      <td>2138-07-21</td>\n",
       "      <td>Send 500mg Vial</td>\n",
       "      <td>Send 500mg Vial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2138-07-18</td>\n",
       "      <td>2138-07-20</td>\n",
       "      <td>Syringe (Neonatal) *D5W*</td>\n",
       "      <td>1 Syringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2191-03-16</td>\n",
       "      <td>2191-03-16</td>\n",
       "      <td>Primaquine Phosphate</td>\n",
       "      <td>26.3MG TAB PK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  startdate    enddate                      drug    prod_strength\n",
       "0           2 2138-07-18 2138-07-20         NEO*IV*Gentamicin      10mg/mL-2mL\n",
       "1           2 2138-07-18 2138-07-21         Ampicillin Sodium       500mg Vial\n",
       "2           2 2138-07-18 2138-07-21           Send 500mg Vial  Send 500mg Vial\n",
       "3           2 2138-07-18 2138-07-20  Syringe (Neonatal) *D5W*        1 Syringe\n",
       "4           4 2191-03-16 2191-03-16      Primaquine Phosphate    26.3MG TAB PK"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prescriptions data\n",
    "\n",
    "df_prescriptions = pd.read_sql_query('''\n",
    "  SELECT subject_id, startdate, enddate, drug, prod_strength\n",
    "  FROM prescriptions\n",
    "  ORDER BY subject_id\n",
    "  LIMIT 10000;\n",
    "''', cnx)\n",
    "\n",
    "print(df_prescriptions.shape)\n",
    "df_prescriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 3 -r 3\n",
    "\n",
    "# Split the dataset in a grouped and stratified manner\n",
    "\n",
    "def StratifiedGroupShuffleSplit(df_main):\n",
    "\n",
    "    df_main = df_main.reindex(np.random.permutation(df_main.index)) # shuffle dataset\n",
    "    \n",
    "    # create empty train, val and test datasets\n",
    "    df_train = pd.DataFrame()\n",
    "    df_val = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "    hparam_mse_wgt = 0.1 # must be between 0 and 1\n",
    "    assert(0 <= hparam_mse_wgt <= 1)\n",
    "    train_proportion = 0.8 # must be between 0 and 1\n",
    "    assert(0 <= train_proportion <= 1)\n",
    "    val_test_proportion = (1-train_proportion)/2\n",
    "\n",
    "    subject_grouped_df_main = df_main.groupby(['subject_id'], sort=False, as_index=False)\n",
    "    gender_grouped_df_main = df_main.groupby('gender').count()[['subject_id']]/len(df_main)*100 \n",
    "    \n",
    "    # function to calculate loss\n",
    "    def calc_mse_loss(df):\n",
    "        grouped_df = df.groupby('gender').count()[['subject_id']]/len(df)*100\n",
    "        df_temp = gender_grouped_df_main.join(grouped_df, on = 'gender', how = 'left', lsuffix = '_main')\n",
    "        df_temp.fillna(0, inplace=True)\n",
    "        df_temp['diff'] = (df_temp['subject_id_main'] - df_temp['subject_id'])**2\n",
    "        mse_loss = np.mean(df_temp['diff'])\n",
    "        return mse_loss\n",
    "    \n",
    "    directory = \"data/preprocessed/\"\n",
    "    \n",
    "    f_train = open(directory + \"src-train.txt\",\"w+\")\n",
    "    f_val = open(directory + \"src-val.txt\",\"w+\")\n",
    "    f_test = open(directory + \"src-test.txt\",\"w+\")\n",
    "    \n",
    "    len_train = 0\n",
    "    len_val = 0\n",
    "    len_test = 0\n",
    "    total_records = 0\n",
    "    i = 0\n",
    "\n",
    "    # loop the groups of subjects one by one\n",
    "    for _, group in subject_grouped_df_main:\n",
    "\n",
    "        total_records = len_train + len_val + len_test\n",
    "        g = pd.DataFrame(group)\n",
    "        subject_id = g['subject_id'].iloc[0]\n",
    "        \n",
    "        pre_left = df_prescriptions['subject_id'].searchsorted(subject_id, 'left')\n",
    "        pre_right = df_prescriptions['subject_id'].searchsorted(subject_id, 'right')\n",
    "        \n",
    "        lab_left = df_labitems['subject_id'].searchsorted(subject_id, 'left')\n",
    "        lab_right = df_labitems['subject_id'].searchsorted(subject_id, 'right')\n",
    "        \n",
    "        g_prescriptions = df_prescriptions[pre_left:pre_right]\n",
    "        g_labitems = df_labitems[lab_left:lab_right]\n",
    "        i += 1\n",
    "        \n",
    "        train = False\n",
    "        val = False\n",
    "        test = False\n",
    "        \n",
    "        # first three groups only\n",
    "        if (i < 4):\n",
    "            if (i == 1):\n",
    "                df_train = df_train.append(g, ignore_index=True)\n",
    "                len_train += len(g)\n",
    "                train = True\n",
    "            elif (i == 2):\n",
    "                df_val = df_val.append(g, ignore_index=True)\n",
    "                len_val += len(g)\n",
    "                val = True\n",
    "            else:\n",
    "                df_test = df_test.append(g, ignore_index=True)\n",
    "                len_test += len(g)\n",
    "                test = True\n",
    "        \n",
    "        # all the other groups except every 500th\n",
    "        if ((i % 1000 != 0) & (i > 3)):\n",
    "            \n",
    "            if (train_proportion > (len_train/total_records)):\n",
    "                df_train = df_train.append(g, ignore_index=True)\n",
    "                len_train += len(g)\n",
    "                train = True\n",
    "            elif (val_test_proportion > (len_val/total_records)):\n",
    "                df_val = df_val.append(g, ignore_index=True)\n",
    "                len_val += len(g)\n",
    "                val = True\n",
    "            else:\n",
    "                df_test = df_test.append(g, ignore_index=True)\n",
    "                len_test += len(g)\n",
    "                test = True\n",
    "        \n",
    "        # every 500th group, balance the groups by proportion and by categories\n",
    "        elif (i % 500 == 0):\n",
    "            \n",
    "            mse_loss_diff_train = calc_mse_loss(df_train) - calc_mse_loss(df_train.append(g, ignore_index=True))\n",
    "            mse_loss_diff_val = calc_mse_loss(df_val) - calc_mse_loss(df_val.append(g, ignore_index=True))\n",
    "            mse_loss_diff_test = calc_mse_loss(df_test) - calc_mse_loss(df_test.append(g, ignore_index=True))\n",
    "\n",
    "            len_diff_train = (train_proportion - (len_train/total_records))\n",
    "            len_diff_val = (val_test_proportion - (len_val/total_records))\n",
    "            len_diff_test = (val_test_proportion - (len_test/total_records)) \n",
    "\n",
    "            len_loss_diff_train = len_diff_train * abs(len_diff_train)\n",
    "            len_loss_diff_val = len_diff_val * abs(len_diff_val)\n",
    "            len_loss_diff_test = len_diff_test * abs(len_diff_test)\n",
    "\n",
    "            loss_train = (hparam_mse_wgt * mse_loss_diff_train) + ((1-hparam_mse_wgt) * len_loss_diff_train)\n",
    "            loss_val = (hparam_mse_wgt * mse_loss_diff_val) + ((1-hparam_mse_wgt) * len_loss_diff_val)\n",
    "            loss_test = (hparam_mse_wgt * mse_loss_diff_test) + ((1-hparam_mse_wgt) * len_loss_diff_test)\n",
    "\n",
    "            if (max(loss_train,loss_val,loss_test) == loss_train):\n",
    "                df_train = df_train.append(g, ignore_index=True)\n",
    "                len_train += len(g)\n",
    "                train = True\n",
    "            elif (max(loss_train,loss_val,loss_test) == loss_val):\n",
    "                df_val = df_val.append(g, ignore_index=True)\n",
    "                len_val += len(g)\n",
    "                val = True\n",
    "            else:\n",
    "                df_test = df_test.append(g, ignore_index=True)\n",
    "                len_test += len(g)\n",
    "                test = True\n",
    "            \n",
    "            print (\"Group \" + str(i) + \". loss_train: \" + str(loss_train) + \" | \" + \"loss_val: \" + str(loss_val) + \" | \" + \"loss_test: \" + str(loss_test) + \" | \")\n",
    "        \n",
    "        # loop through every row in the group to get relevant prescriptions and lab items before appending to file\n",
    "        for j, row in enumerate(g.itertuples()):\n",
    "            \n",
    "            chartdate = datetime.combine(row[6], datetime.min.time())\n",
    "            cutoff = chartdate\n",
    "            chartdate = cutoff + timedelta(days=1)    \n",
    "            \n",
    "            lab_condition = np.logical_and((g_labitems.charttime >= cutoff),\n",
    "                                           (g_labitems.charttime < chartdate))\n",
    "            lab_items = g_labitems[lab_condition]\n",
    "            lab_items = lab_items.sort_values(by=['charttime'], ascending=False)\n",
    "            \n",
    "            pre_condition = np.logical_and((g_prescriptions.startdate >= cutoff),\n",
    "                                           (g_prescriptions.startdate < chartdate))\n",
    "            prescriptions = g_prescriptions[pre_condition]\n",
    "            prescriptions = prescriptions.sort_values(by=['startdate'], ascending=False)\n",
    "            \n",
    "            lab_items_list = \"\"\n",
    "            lab_items_length = len(lab_items)\n",
    "            if (lab_items_length > 0):\n",
    "                for k, lab_row in enumerate(lab_items.itertuples()):\n",
    "                    flag = \"\"\n",
    "                    if (pd.isna(lab_row[5]) == False):\n",
    "                        flag = \" , \" + str(lab_row[5])\n",
    "\n",
    "                    lab_items_list += str(lab_row[6]) + \" , \" + str(lab_row[3]) + \" , \" + str(lab_row[4]) + flag\n",
    "                    if (k != (lab_items_length - 1)):\n",
    "                        lab_items_list += \" | \"\n",
    "\n",
    "            prescriptions_list = \"\"\n",
    "            prescriptions_length = len(prescriptions)\n",
    "            if (prescriptions_length > 0):\n",
    "                for k, pre_row in enumerate(prescriptions.itertuples()):\n",
    "                    prescriptions_list += str(pre_row[4]) + \" , \" + str(pre_row[5])\n",
    "                    if (k != (prescriptions_length - 1)):\n",
    "                        prescriptions_list += \" | \"\n",
    "            \n",
    "            if (train == True):\n",
    "                f_train.write(str(row[10]) + \" <H> \" + str(row[3]) + \" <G> \" + str(row[8]) + \" <A> \" + \n",
    "                    prescriptions_list + \" <M> \" + lab_items_list + \" <L>\" + \"\\n\")\n",
    "            elif (val == True):\n",
    "                f_val.write(str(row[10]) + \" <H> \" + \" <T> \" + str(row[3]) + \" <G> \" + str(row[8]) + \" <A> \" + \n",
    "                    prescriptions_list + \" <M> \" + lab_items_list + \" <L>\" + \"\\n\")\n",
    "            else:\n",
    "                f_test.write(str(row[10]) + \" <H> \" + \" <T> \" + str(row[3]) + \" <G> \" + str(row[8]) + \" <A> \" + \n",
    "                    prescriptions_list + \" <M> \" + lab_items_list + \" <L>\" + \"\\n\")\n",
    "        \n",
    "        if (i % 100 == 0):\n",
    "            print (i)\n",
    "    \n",
    "    f_train.close()\n",
    "    f_val.close()\n",
    "    f_test.close()\n",
    "    \n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2a5b37b65668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedGroupShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-41056a5f0c1d>\u001b[0m in \u001b[0;36mStratifiedGroupShuffleSplit\u001b[0;34m(df_main)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                            (g_labitems.charttime < chartdate))\n\u001b[1;32m    139\u001b[0m             \u001b[0mlab_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_labitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlab_condition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mlab_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'charttime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             pre_condition = np.logical_and((g_prescriptions.startdate >= cutoff),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4727\u001b[0m         new_data = self._data.take(indexer,\n\u001b[1;32m   4728\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4729\u001b[0;31m                                    verify=False)\n\u001b[0m\u001b[1;32m   4730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                 'the axis length')\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m   1350\u001b[0m                                     axis=axis, allow_dups=True)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mtaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     def _assert_take_fillable(self, values, indices, allow_fill=True,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Ensure we are not returning an Int64Index with float data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         return (super(NumericIndex, self)._shallow_copy(values=values,\n\u001b[1;32m     73\u001b[0m                                                         **kwargs))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy_with_infer\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPandasArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;31m# ensure users don't accidentally put a PandasArray in an index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "src_train, src_val, src_test = StratifiedGroupShuffleSplit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
