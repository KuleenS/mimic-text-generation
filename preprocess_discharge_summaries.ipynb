{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Discharge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import string\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "import random\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the mimic database and set the search path to the 'mimiciii' schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbschema='mimiciii'\n",
    "cnx = sqlalchemy.create_engine('postgresql+psycopg2://aa5118:mimic@localhost:5432/mimic',\n",
    "                    connect_args={'options': '-csearch_path={}'.format(dbschema)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the discharge summary notes joined on to patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>145834</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2101-10-31</td>\n",
       "      <td>44005</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2143-05-12</td>\n",
       "      <td>F</td>\n",
       "      <td>185777</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2191-03-23</td>\n",
       "      <td>4788</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2109-06-21</td>\n",
       "      <td>F</td>\n",
       "      <td>107064</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2175-06-15</td>\n",
       "      <td>20825</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>57115</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Name:  [**Known lastname 10050**], [**Known fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-13</td>\n",
       "      <td>20070</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Admission Date:  [**2149-11-9**]       Dischar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender  hadm_id           category  chartdate  \\\n",
       "0           3 2025-04-11      M   145834  Discharge summary 2101-10-31   \n",
       "1           4 2143-05-12      F   185777  Discharge summary 2191-03-23   \n",
       "2           6 2109-06-21      F   107064  Discharge summary 2175-06-15   \n",
       "3           9 2108-01-26      M   150750  Discharge summary 2149-11-14   \n",
       "4           9 2108-01-26      M   150750  Discharge summary 2149-11-13   \n",
       "\n",
       "   row_id  age_at_noteevent                                               text  \n",
       "0   44005              77.0  Admission Date:  [**2101-10-20**]     Discharg...  \n",
       "1    4788              48.0  Admission Date:  [**2191-3-16**]     Discharge...  \n",
       "2   20825              66.0  Admission Date: [**2175-5-30**]        Dischar...  \n",
       "3   57115              42.0  Name:  [**Known lastname 10050**], [**Known fi...  \n",
       "4   20070              42.0  Admission Date:  [**2149-11-9**]       Dischar...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "  SELECT\n",
    "      p.subject_id, p.dob, p.gender,\n",
    "      n.hadm_id, n.category, n.chartdate, n.row_id,\n",
    "      ROUND((cast(chartdate as date) - cast(dob as date)) / 365.242,0)\n",
    "          AS age_at_noteevent,\n",
    "      n.text\n",
    "  FROM patients p \n",
    "  INNER JOIN noteevents n \n",
    "  ON p.subject_id = n.subject_id\n",
    "  WHERE ROUND((cast(chartdate as date) - cast(dob as date)) / 365.242,0) > 14\n",
    "  AND n.category = 'Discharge summary'\n",
    "  ORDER BY subject_id\n",
    "  --LIMIT 1000;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sqlalchemy.text(sql), cnx)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change data type of age to the smallest possible type of integer to save memory and get rid of decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>145834</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2101-10-31</td>\n",
       "      <td>44005</td>\n",
       "      <td>77</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2143-05-12</td>\n",
       "      <td>F</td>\n",
       "      <td>185777</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2191-03-23</td>\n",
       "      <td>4788</td>\n",
       "      <td>48</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2109-06-21</td>\n",
       "      <td>F</td>\n",
       "      <td>107064</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2175-06-15</td>\n",
       "      <td>20825</td>\n",
       "      <td>66</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>57115</td>\n",
       "      <td>42</td>\n",
       "      <td>Name:  [**Known lastname 10050**], [**Known fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2108-01-26</td>\n",
       "      <td>M</td>\n",
       "      <td>150750</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2149-11-13</td>\n",
       "      <td>20070</td>\n",
       "      <td>42</td>\n",
       "      <td>Admission Date:  [**2149-11-9**]       Dischar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender  hadm_id           category  chartdate  \\\n",
       "0           3 2025-04-11      M   145834  Discharge summary 2101-10-31   \n",
       "1           4 2143-05-12      F   185777  Discharge summary 2191-03-23   \n",
       "2           6 2109-06-21      F   107064  Discharge summary 2175-06-15   \n",
       "3           9 2108-01-26      M   150750  Discharge summary 2149-11-14   \n",
       "4           9 2108-01-26      M   150750  Discharge summary 2149-11-13   \n",
       "\n",
       "   row_id  age_at_noteevent                                               text  \n",
       "0   44005                77  Admission Date:  [**2101-10-20**]     Discharg...  \n",
       "1    4788                48  Admission Date:  [**2191-3-16**]     Discharge...  \n",
       "2   20825                66  Admission Date: [**2175-5-30**]        Dischar...  \n",
       "3   57115                42  Name:  [**Known lastname 10050**], [**Known fi...  \n",
       "4   20070                42  Admission Date:  [**2149-11-9**]       Dischar...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age_at_noteevent'] = pd.to_numeric(df['age_at_noteevent'], downcast='integer')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55404, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55404 'adult' (15 or over) discharge summaries - this is what we expect from our exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(list(df.head(1000)['text']))\n",
    "#text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following punctuation marks frequently appear in the middle of words or between words without spacing meaning they are missed by the tokenizer. What we need to is to split the tokens on these punctuation marks after we have tokenized. We then retokenize. This will substantially decreases the number of our unique words which we will replace with <UNK>\n",
    "\n",
    "- ampersand\n",
    "- brackets\n",
    "- colons\n",
    "- forward slashes(make sure to leave dates alone though)\n",
    "- full stops\n",
    "- hyphens\n",
    "- equals signs\n",
    "- semicolons\n",
    "- plus signs\n",
    "\n",
    "Also perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "date_regex = re.compile(r'([0-9])-([0-9][0-9]?)-([0-9])') # change date format so spacy can recognise\n",
    "newline_regex = re.compile(r'(\\\\n){3,}') # cap number of consecutive newline characters to 2\n",
    "newline_regex2 = re.compile(r'(\\\\r){3,}') # cap number of consecutive newline characters to 2\n",
    "\n",
    "bracket_regex = re.compile(r'(.)(\\()(.)')\n",
    "bracket_regex2 = re.compile(r'(.)(\\))(.)')\n",
    "slash_regex = re.compile(r'(.)(\\/)([^0-9])')\n",
    "slash_regex2 = re.compile(r'([^0-9])(\\/)(.)')\n",
    "equals_regex = re.compile(r'(.)(=)(.)')\n",
    "colon_regex = re.compile(r'(.)(:)(.)')\n",
    "sq_bracket_regex = re.compile(r'(.)(\\[)(.)')\n",
    "dash_regex = re.compile(r'(.)(-)(.)')\n",
    "plus_regex = re.compile(r'(.)(\\+)(.)')\n",
    "amp_regex = re.compile(r'(.)(&)(.)')\n",
    "\n",
    "dot_regex = re.compile(r'([^0-9.])\\.(\\S[^0-9.])')\n",
    "semicol_regex = re.compile(r'(.);(.)')\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def tokenise_text(text):\n",
    "    global counter\n",
    "    \n",
    "    text = str(text)\n",
    "    text = date_regex.sub(r'\\1/\\2/\\3',text)\n",
    "    text = newline_regex.sub(r'\\\\n\\\\n',text)\n",
    "    text = newline_regex2.sub(r'\\\\n\\\\n',text)\n",
    "    \n",
    "    text = text.replace(\"[**\",\"[\").replace(\"**]\",\"]\")\n",
    "    \n",
    "    #text = text.lower()\n",
    "    tokens = nlp.tokenizer(text)\n",
    "    tokenised_text = \"\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        tokenised_text = tokenised_text + str(token) + \" \"\n",
    "    \n",
    "    tokenised_text = tokenised_text.replace(\"\\n\",\" <PAR> \")\n",
    "    \n",
    "    tokenised_text = bracket_regex.sub(r'\\1 \\2\\3',tokenised_text)\n",
    "    tokenised_text = bracket_regex2.sub(r'\\1\\2 \\3',tokenised_text)\n",
    "    tokenised_text = slash_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = slash_regex2.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = equals_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = colon_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = sq_bracket_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dash_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dash_regex.sub(r'\\1 \\2 \\3',tokenised_text) # dash twice because sometimes it appears twice\n",
    "    tokenised_text = plus_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = amp_regex.sub(r'\\1 \\2 \\3',tokenised_text)\n",
    "    tokenised_text = dot_regex.sub(r'\\1 \\2',tokenised_text)\n",
    "    tokenised_text = semicol_regex.sub(r'\\1 \\2',tokenised_text)\n",
    "\n",
    "    tokenised_text = ' '.join(tokenised_text.split())\n",
    "    \n",
    "    counter += 1\n",
    "    if (counter % 100) == 0:\n",
    "        print (counter)\n",
    "    \n",
    "    return tokenised_text\n",
    "text = tokenise_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we isolate the tokens which appear 3 times or fewer. They are mostly misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case(u'<PAR>', [{ORTH: u'<PAR>'}])\n",
    "nlp.tokenizer.add_special_case(u'<UNK>', [{ORTH: u'<UNK>'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'ll\",\n",
       " \"'re\",\n",
       " '-\"in',\n",
       " '--100/52',\n",
       " '--klonopin',\n",
       " '--lithium',\n",
       " '--melatonin',\n",
       " '--zydis',\n",
       " '--|',\n",
       " '-10',\n",
       " '-100',\n",
       " '-101',\n",
       " '-102',\n",
       " '-103',\n",
       " '-104',\n",
       " '-105',\n",
       " '-108',\n",
       " '-111',\n",
       " '-114',\n",
       " '-12',\n",
       " '-120',\n",
       " '-13',\n",
       " '-14',\n",
       " '-155',\n",
       " '-20',\n",
       " '-23',\n",
       " '-24',\n",
       " '-29',\n",
       " '-31',\n",
       " '-9',\n",
       " '-92',\n",
       " '-94',\n",
       " '-95',\n",
       " '-98',\n",
       " '-99',\n",
       " '->1',\n",
       " '->106/59',\n",
       " '->119',\n",
       " '->15',\n",
       " '->16.3',\n",
       " '->2',\n",
       " '->23.8',\n",
       " '->29.0',\n",
       " '->3',\n",
       " '->30.1',\n",
       " '->44',\n",
       " '->60',\n",
       " '->66',\n",
       " '->7.37/39/76',\n",
       " '->98',\n",
       " '->linezolid',\n",
       " '->therefore',\n",
       " '-apply',\n",
       " '-atovaquone',\n",
       " '-basic',\n",
       " '-complicating',\n",
       " '-doses',\n",
       " '-due',\n",
       " '-in',\n",
       " '-increaed',\n",
       " '-last',\n",
       " '-metastatic',\n",
       " '-per',\n",
       " '-please',\n",
       " '-pt',\n",
       " '-qt',\n",
       " '-r',\n",
       " '-she',\n",
       " '-sinus',\n",
       " '-started',\n",
       " '-symptoms',\n",
       " '-two',\n",
       " '-we',\n",
       " '-you',\n",
       " '.01',\n",
       " '.01%gel',\n",
       " '.018',\n",
       " '.02',\n",
       " '.02.914',\n",
       " '.025',\n",
       " '.035',\n",
       " '.04',\n",
       " '.05',\n",
       " '.06',\n",
       " '.100',\n",
       " '.11',\n",
       " '.112mcg',\n",
       " '.125',\n",
       " '.20',\n",
       " '.22',\n",
       " '.24',\n",
       " '.29',\n",
       " '.36',\n",
       " '.37',\n",
       " '.38',\n",
       " '.46',\n",
       " '.48',\n",
       " '.50',\n",
       " '.60',\n",
       " '.62',\n",
       " '.75qd',\n",
       " '.77',\n",
       " '.80/5',\n",
       " '.91',\n",
       " '.92',\n",
       " '/07',\n",
       " '/906',\n",
       " '/vasculitis',\n",
       " '<3',\n",
       " '@17',\n",
       " '@1pm',\n",
       " '@3',\n",
       " '@70bpm',\n",
       " '@80',\n",
       " '@osh',\n",
       " '\\\\11.0',\n",
       " 'a0.7',\n",
       " 'a2',\n",
       " 'a500',\n",
       " 'aad',\n",
       " 'abdm',\n",
       " 'abdminal',\n",
       " 'abdmonial',\n",
       " 'abdom',\n",
       " 'abdoment',\n",
       " 'abdomin',\n",
       " 'abdominopelvic',\n",
       " 'abdomoinal',\n",
       " 'abduct',\n",
       " 'aberrancy',\n",
       " 'aberrant',\n",
       " 'abilify',\n",
       " 'abilities',\n",
       " 'abis',\n",
       " 'abl',\n",
       " 'ablated',\n",
       " 'abn',\n",
       " 'abnlty',\n",
       " 'abnorm',\n",
       " 'abnormalites',\n",
       " 'abo',\n",
       " 'abodmen',\n",
       " 'abodominal',\n",
       " 'abominal',\n",
       " 'abormality',\n",
       " 'abortion',\n",
       " 'abruption',\n",
       " 'abruptly',\n",
       " 'absense',\n",
       " 'absolutely',\n",
       " 'absorbs',\n",
       " 'absorbtion',\n",
       " 'abstinent',\n",
       " 'abused',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abut',\n",
       " 'abuts',\n",
       " 'abutting',\n",
       " 'abvd',\n",
       " 'abxs',\n",
       " 'acalculous',\n",
       " 'acanthocytes',\n",
       " 'acanthosis',\n",
       " 'acc',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accentuated',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accfess',\n",
       " 'accidental',\n",
       " 'accolate',\n",
       " 'accomodation',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accordance',\n",
       " 'accounting',\n",
       " 'accredo',\n",
       " 'accu',\n",
       " 'accuchecks',\n",
       " 'acculink',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accunet',\n",
       " 'accurately',\n",
       " 'acd',\n",
       " 'acdf',\n",
       " 'acebutolol',\n",
       " 'acenitobacter',\n",
       " 'acetabula',\n",
       " 'acetabulum',\n",
       " 'acetominophen',\n",
       " 'acetonide',\n",
       " 'ach']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp.tokenizer(text.lower())\n",
    "words = [token.text for token in doc if token.is_punct != True and token.is_digit != True  and ((token.text)[0]).isdigit() != True]\n",
    "\n",
    "word_freq = dict(Counter(words))\n",
    "infreq_words = [word for word in word_freq.keys() if word_freq[word] <= 3]\n",
    "print(len(infreq_words))\n",
    "sorted(infreq_words)[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try and see if we can correct the misspellings using the `pyspellchecker` library by using the Levenshtein Distance algorithm and comparing against a dictionary. We first add the words with >3 occurrence to our dictionary. This is because they include a lot of scientific/medical terms which might not already be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = [word for word in word_freq.keys() if word_freq[word] > 3]\n",
    "add_to_dictionary = \" \".join(freq_words)\n",
    "f=open(\"data/mimic_dict.txt\", \"w+\")\n",
    "f.write(add_to_dictionary)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "spell.distance = 1  # set the distance parameter to just 1 edit away\n",
    "spell.word_frequency.load_text_file('data/mimic_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled = spell.unknown(infreq_words)\n",
    "misspell_dict = {}\n",
    "for i, word in enumerate(misspelled):\n",
    "    if (word != spell.correction(word)):\n",
    "        misspell_dict[word] = spell.correction(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3328"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misspell_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have correct spellings for over 3000 words in our dictionary that occurred <= 3 times. We will now implement this in our new tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
